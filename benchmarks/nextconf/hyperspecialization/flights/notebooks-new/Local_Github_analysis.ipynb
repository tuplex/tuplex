{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching 2 files from bbsn00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('data', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011-02-12-10.json.gz                         100%  181KB 229.0KB/s   00:00    \n"
     ]
    }
   ],
   "source": [
    "!scp tuplex@bbsn00:/disk/download/data/2011-02-12-10.json.gz data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-12-10.json.gz                         100%   67MB   2.9MB/s   00:23    \n"
     ]
    }
   ],
   "source": [
    "!scp tuplex@bbsn00:/disk/download/data/2021-02-12-10.json.gz data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-06-05-10.json.gz                         100% 9137KB   2.2MB/s   00:04    \n"
     ]
    }
   ],
   "source": [
    "!scp tuplex@bbsn00:/disk/download/data/2015-06-05-10.json.gz data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011-02-12-10.json    2015-06-05-10.json.gz 2021-02-12-10.json.gz\r\n",
      "2011-02-12-10.json.gz 2021-02-12-10.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  120737 data/2021-02-12-10.json\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l data/2021-02-12-10.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1057 data/2011-02-12-10.json\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l data/2011-02-12-10.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   34099 data/2015-06-05-10.json.gz\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l data/2015-06-05-10.json.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation 1:\n",
    "Amount of data changed a lot. Therefore good idea to process differently? I.e., did average #keys/#length change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "with open('data/2021-02-12-10.json') as fp:\n",
    "    lines = fp.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nlines': 1057,\n",
       " 'avg_line_length': 881.2147587511826,\n",
       " 'path': 'data/2011-02-12-10.json',\n",
       " 'avg_nkeys': 7.114474929044466,\n",
       " 'min_nkeys': 7,\n",
       " 'max_nkeys': 8,\n",
       " 'nunique_1st_level': {7: 0.8855250709555346, 8: 0.11447492904446546},\n",
       " 'nunique_2nd_level': {11: 0.0008377720633448766, 13: 0.00010830173041103639}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_global_stats(path):\n",
    "    with open(path) as fp:\n",
    "        lines = fp.readlines()\n",
    "    \n",
    "    n_lines = len(lines)\n",
    "    n_length = sum(map(lambda x: len(x.strip()), lines))\n",
    "    n_key_lengths = np.array([len(json.loads(line).keys()) for line in lines])\n",
    "    avg_nkeys = n_key_lengths.mean()\n",
    "    min_nkeys = n_key_lengths.min()\n",
    "    max_nkeys = n_key_lengths.max()\n",
    "    uniq_nkeys, key_counts = np.unique(n_key_lengths, return_counts=True)\n",
    "    key_counts = key_counts.astype(np.float64) / n_lines\n",
    "    uniq_nkeys = dict(zip(list(uniq_nkeys), list(key_counts)))\n",
    "    \n",
    "    # count 2nd level keys!\n",
    "    def get_2nd_level_keys(line):\n",
    "        d = json.loads(line)\n",
    "        n = 0\n",
    "        for v in d.values():\n",
    "            if isinstance(v, dict):\n",
    "                n += len(v.keys())\n",
    "            else:\n",
    "                n += 1\n",
    "        return n\n",
    "    \n",
    "    n_2key_lengths = np.array([get_2nd_level_keys(line) for line in lines])\n",
    "    u, c = np.unique(n_2key_lengths, return_counts=True)\n",
    "    c = key_counts.astype(np.float64) / n_lines\n",
    "    uniq_2_keys = dict(zip(list(u), list(c)))\n",
    "    \n",
    "    return {'nlines' : n_lines,\n",
    "            'avg_line_length' : n_length / n_lines,\n",
    "            'path' : path,\n",
    "           'avg_nkeys' : avg_nkeys,\n",
    "           'min_nkeys' : min_nkeys,\n",
    "           'max_nkeys' : max_nkeys,\n",
    "           'nunique_1st_level' : uniq_nkeys,\n",
    "           'nunique_2nd_level': uniq_2_keys}\n",
    "\n",
    "get_global_stats('data/2011-02-12-10.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/2021-02-12-10.json') as fp:\n",
    "    lines = fp.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CommitCommentEvent': 0.005321802760685182,\n",
       " 'CreateEvent': 0.12032263429236655,\n",
       " 'DeleteEvent': 0.02141194079494429,\n",
       " 'ForkEvent': 0.033552303342757356,\n",
       " 'GollumEvent': 0.011807749875270248,\n",
       " 'IssueCommentEvent': 0.09504407117911193,\n",
       " 'IssuesEvent': 0.04652419757192749,\n",
       " 'MemberEvent': 0.004032928654581739,\n",
       " 'PublicEvent': 0.0010394146016963247,\n",
       " 'PullRequestEvent': 0.055380009978380176,\n",
       " 'PullRequestReviewCommentEvent': 0.017919507733244636,\n",
       " 'PushEvent': 0.4936387826376185,\n",
       " 'ReleaseEvent': 0.0035340096457675036,\n",
       " 'WatchEvent': 0.0904706469316481}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_type = np.array([json.loads(line)['type'] for line in lines])\n",
    "u, c = np.unique(event_type, return_counts=True)\n",
    "c = c.astype(np.float64) / len(event_type)\n",
    "dict(zip(u, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CommitCommentEvent': 0.003784295175023652,\n",
       " 'CreateEvent': 0.1901608325449385,\n",
       " 'DeleteEvent': 0.010406811731315043,\n",
       " 'DownloadEvent': 0.000946073793755913,\n",
       " 'FollowEvent': 0.039735099337748346,\n",
       " 'ForkEvent': 0.039735099337748346,\n",
       " 'GistEvent': 0.03595080416272469,\n",
       " 'GollumEvent': 0.01229895931882687,\n",
       " 'IssuesEvent': 0.03595080416272469,\n",
       " 'MemberEvent': 0.006622516556291391,\n",
       " 'PullRequestEvent': 0.019867549668874173,\n",
       " 'PushEvent': 0.4966887417218543,\n",
       " 'WatchEvent': 0.10785241248817408}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/2011-02-12-10.json') as fp:\n",
    "    lines = fp.readlines()\n",
    "    \n",
    "    \n",
    "event_type = np.array([json.loads(line)['type'] for line in lines])\n",
    "u, c = np.unique(event_type, return_counts=True)\n",
    "c = c.astype(np.float64) / len(event_type)\n",
    "dict(zip(u, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CommitCommentEvent': 0.005321802760685182,\n",
       " 'CreateEvent': 0.12032263429236655,\n",
       " 'DeleteEvent': 0.02141194079494429,\n",
       " 'ForkEvent': 0.033552303342757356,\n",
       " 'GollumEvent': 0.011807749875270248,\n",
       " 'IssueCommentEvent': 0.09504407117911193,\n",
       " 'IssuesEvent': 0.04652419757192749,\n",
       " 'MemberEvent': 0.004032928654581739,\n",
       " 'PublicEvent': 0.0010394146016963247,\n",
       " 'PullRequestEvent': 0.055380009978380176,\n",
       " 'PullRequestReviewCommentEvent': 0.017919507733244636,\n",
       " 'PushEvent': 0.4936387826376185,\n",
       " 'ReleaseEvent': 0.0035340096457675036,\n",
       " 'WatchEvent': 0.0904706469316481}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/2015-06-05-10.json') as fp:\n",
    "    lines = fp.readlines()\n",
    "    \n",
    "    \n",
    "event_type = np.array([json.loads(line)['type'] for line in lines])\n",
    "u, c = np.unique(event_type, return_counts=True)\n",
    "c = c.astype(np.float64) / len(event_type)\n",
    "dict(zip(u, c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's investigate PushEvents (since they're the majority!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/2015-06-05-10.json'\n",
    "path = 'data/2021-02-12-10.json'\n",
    "with open(path) as fp:\n",
    "    lines = fp.readlines()\n",
    "    \n",
    "    rows = [json.loads(line) for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_2 = list(filter(lambda x: x['type'] == 'PushEvent', rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '15162035923',\n",
       " 'type': 'PushEvent',\n",
       " 'actor': {'id': 20182680,\n",
       "  'login': 'LinuxServer-CI',\n",
       "  'display_login': 'LinuxServer-CI',\n",
       "  'gravatar_id': '',\n",
       "  'url': 'https://api.github.com/users/LinuxServer-CI',\n",
       "  'avatar_url': 'https://avatars.githubusercontent.com/u/20182680?'},\n",
       " 'repo': {'id': 87807234,\n",
       "  'name': 'linuxserver/docker-duplicati',\n",
       "  'url': 'https://api.github.com/repos/linuxserver/docker-duplicati'},\n",
       " 'payload': {'push_id': 6521264030,\n",
       "  'size': 1,\n",
       "  'distinct_size': 1,\n",
       "  'ref': 'refs/heads/development',\n",
       "  'head': '9828bf14dc79c44ba1754e8d3aa7a294df0c48d9',\n",
       "  'before': '58c191a3b0bf5aa8b96b5f2b17c232f81b784b9b',\n",
       "  'commits': [{'sha': '9828bf14dc79c44ba1754e8d3aa7a294df0c48d9',\n",
       "    'author': {'name': 'LinuxServer-CI',\n",
       "     'email': '5a4fe08359c7f97380e408c717ef42c86939cd86@linuxserver.io'},\n",
       "    'message': 'Bot Updating Templated Files',\n",
       "    'distinct': True,\n",
       "    'url': 'https://api.github.com/repos/linuxserver/docker-duplicati/commits/9828bf14dc79c44ba1754e8d3aa7a294df0c48d9'}]},\n",
       " 'public': True,\n",
       " 'created_at': '2021-02-12T10:00:00Z',\n",
       " 'org': {'id': 12324908,\n",
       "  'login': 'linuxserver',\n",
       "  'gravatar_id': '',\n",
       "  'url': 'https://api.github.com/orgs/linuxserver',\n",
       "  'avatar_url': 'https://avatars.githubusercontent.com/u/12324908?'}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_2[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 12324908,\n",
       " 'login': 'linuxserver',\n",
       " 'gravatar_id': '',\n",
       " 'url': 'https://api.github.com/orgs/linuxserver',\n",
       " 'avatar_url': 'https://avatars.githubusercontent.com/u/12324908?'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_2[10]['org']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13383, 56592)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_org_pushes = len(list(filter(lambda x: x['type'] == 'PushEvent' and 'org' in x.keys(), rows)))\n",
    "n_org_pushes, len(rows_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe different org distribution? Could this lead to a difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '2866927111',\n",
       " 'type': 'PushEvent',\n",
       " 'actor': {'id': 9982176,\n",
       "  'login': 'roxyavgfli',\n",
       "  'gravatar_id': '',\n",
       "  'url': 'https://api.github.com/users/roxyavgfli',\n",
       "  'avatar_url': 'https://avatars.githubusercontent.com/u/9982176?'},\n",
       " 'repo': {'id': 36805194,\n",
       "  'name': 'roxyavgfli/Light_Bot_Project_Grp6',\n",
       "  'url': 'https://api.github.com/repos/roxyavgfli/Light_Bot_Project_Grp6'},\n",
       " 'payload': {'push_id': 686101578,\n",
       "  'size': 3,\n",
       "  'distinct_size': 3,\n",
       "  'ref': 'refs/heads/master',\n",
       "  'head': '2bd8b6c87a7087f5e9e870edeb8c73fb678d431b',\n",
       "  'before': '3e14147cfab02a608172b01e19e7cbcc55015e26',\n",
       "  'commits': [{'sha': 'a8011d422740912bd635e8c8b42c757f6de4dc85',\n",
       "    'author': {'email': '093c1c14ef90f2c50d86cf4b78c754e6ba763b38@gmail.com',\n",
       "     'name': 'Vial-Grelier Aymeric'},\n",
       "    'message': \"Merge branch 'master' into aym-dev\",\n",
       "    'distinct': True,\n",
       "    'url': 'https://api.github.com/repos/roxyavgfli/Light_Bot_Project_Grp6/commits/a8011d422740912bd635e8c8b42c757f6de4dc85'},\n",
       "   {'sha': 'b09de66e0335f17005ed0984220275e805551ea8',\n",
       "    'author': {'email': '093c1c14ef90f2c50d86cf4b78c754e6ba763b38@gmail.com',\n",
       "     'name': 'Vial-Grelier Aymeric'},\n",
       "    'message': 'main qui marche\\n\\nSigned-off-by: Vial-Grelier Aymeric <aymvial@gmail.com>',\n",
       "    'distinct': True,\n",
       "    'url': 'https://api.github.com/repos/roxyavgfli/Light_Bot_Project_Grp6/commits/b09de66e0335f17005ed0984220275e805551ea8'},\n",
       "   {'sha': '2bd8b6c87a7087f5e9e870edeb8c73fb678d431b',\n",
       "    'author': {'email': '093c1c14ef90f2c50d86cf4b78c754e6ba763b38@gmail.com',\n",
       "     'name': 'Vial-Grelier Aymeric'},\n",
       "    'message': \"Merge branch 'aym-dev'\",\n",
       "    'distinct': True,\n",
       "    'url': 'https://api.github.com/repos/roxyavgfli/Light_Bot_Project_Grp6/commits/2bd8b6c87a7087f5e9e870edeb8c73fb678d431b'}]},\n",
       " 'public': True,\n",
       " 'created_at': '2015-06-05T10:00:03Z'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_2[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query:\n",
    "\n",
    "When users from which country usually fork your work? Timewise?\n",
    "    \n",
    "Query: \n",
    "\n",
    "Create fork/star network out of users - per month to show change? (requires groupby)\n",
    "\n",
    "Query:\n",
    "\n",
    "What are the most popular English swearwords on Github? Did swearword use decrease over the years?\n",
    "\n",
    "Query:\n",
    "\n",
    "How long do PRs usually take to get merged? Is there a correlation between larger repos/bigger project and speed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check how the event types differ in frequency for the different github files. I.e., is there a pattern?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'forkee': {'id': 338280635,\n",
       "  'node_id': 'MDEwOlJlcG9zaXRvcnkzMzgyODA2MzU=',\n",
       "  'name': 'OnlineClassesBot',\n",
       "  'full_name': 'PROHackerr/OnlineClassesBot',\n",
       "  'private': False,\n",
       "  'owner': {'login': 'PROHackerr',\n",
       "   'id': 75305464,\n",
       "   'node_id': 'MDQ6VXNlcjc1MzA1NDY0',\n",
       "   'avatar_url': 'https://avatars.githubusercontent.com/u/75305464?v=4',\n",
       "   'gravatar_id': '',\n",
       "   'url': 'https://api.github.com/users/PROHackerr',\n",
       "   'html_url': 'https://github.com/PROHackerr',\n",
       "   'followers_url': 'https://api.github.com/users/PROHackerr/followers',\n",
       "   'following_url': 'https://api.github.com/users/PROHackerr/following{/other_user}',\n",
       "   'gists_url': 'https://api.github.com/users/PROHackerr/gists{/gist_id}',\n",
       "   'starred_url': 'https://api.github.com/users/PROHackerr/starred{/owner}{/repo}',\n",
       "   'subscriptions_url': 'https://api.github.com/users/PROHackerr/subscriptions',\n",
       "   'organizations_url': 'https://api.github.com/users/PROHackerr/orgs',\n",
       "   'repos_url': 'https://api.github.com/users/PROHackerr/repos',\n",
       "   'events_url': 'https://api.github.com/users/PROHackerr/events{/privacy}',\n",
       "   'received_events_url': 'https://api.github.com/users/PROHackerr/received_events',\n",
       "   'type': 'User',\n",
       "   'site_admin': False},\n",
       "  'html_url': 'https://github.com/PROHackerr/OnlineClassesBot',\n",
       "  'description': 'My simple Python Program which attends my Online Classes',\n",
       "  'fork': True,\n",
       "  'url': 'https://api.github.com/repos/PROHackerr/OnlineClassesBot',\n",
       "  'forks_url': 'https://api.github.com/repos/PROHackerr/OnlineClassesBot/forks',\n",
       "  'keys_url': 'https://api.github.com/repos/PROHackerr/OnlineClassesBot/keys{/key_id}',\n",
       "  'collaborators_url': 'https://api.github.com/repos/PROHackerr/OnlineClassesBot/collaborators{/collaborator}',\n",
       "  'teams_url': 'https://api.github.com/repos/PROHackerr/OnlineClassesBot/teams',\n",
       "  'hooks_url': 'https://api.github.com/repos/PROHackerr/OnlineClassesBot/hooks',\n",
       "  'issue_events_url': 'https://api.github.com/repos/PROHackerr/OnlineClassesBot/issues/events{/number}',\n",
       "  'events_url': 'https://api.github.com/repos/PROHackerr/OnlineClassesBot/events',\n",
       "  'assignees_url': 'https://api.github.com/repos/PROHackerr/OnlineClassesBot/assignees{/user}',\n",
       "  'branches_url': 'https://api.github.com/repos/PROHackerr/OnlineClassesBot/branches{/branch}',\n",
       "  'tags_url': 'https://api.github.com/repos/PROHackerr/OnlineClassesBot/tags',\n",
       "  'blobs_url': 'https://api.github.com/repos/PROHackerr/OnlineClassesBot/git/blobs{/sha}',\n",
       "  'git_tags_url': 'https://api.github.com/repos/PROHackerr/OnlineClassesBot/git/tags{/sha}',\n",
       "  'git_refs_url': 'https://api.github.com/repos/PROHackerr/OnlineClassesBot/git/refs{/sha}',\n",
       "  'trees_url': 'https://api.github.com/repos/PROHackerr/OnlineClassesBot/git/trees{/sha}',\n",
       "  'statuses_url': 'https://api.github.com/repos/PROHackerr/OnlineClassesBot/statuses/{sha}',\n",
       "  'languages_url': 'https://api.github.com/repos/PROHackerr/OnlineClassesBot/languages',\n",
       "  'stargazers_url': 'https://api.github.com/repos/PROHackerr/OnlineClassesBot/stargazers',\n",
       "  'contributors_url': 'https://api.github.com/repos/PROHackerr/OnlineClassesBot/contributors',\n",
       "  'subscribers_url': 'https://api.github.com/repos/PROHackerr/OnlineClassesBot/subscribers',\n",
       "  'subscription_url': 'https://api.github.com/repos/PROHackerr/OnlineClassesBot/subscription',\n",
       "  'commits_url': 'https://api.github.com/repos/PROHackerr/OnlineClassesBot/commits{/sha}',\n",
       "  'git_commits_url': 'https://api.github.com/repos/PROHackerr/OnlineClassesBot/git/commits{/sha}',\n",
       "  'comments_url': 'https://api.github.com/repos/PROHackerr/OnlineClassesBot/comments{/number}',\n",
       "  'issue_comment_url': 'https://api.github.com/repos/PROHackerr/OnlineClassesBot/issues/comments{/number}',\n",
       "  'contents_url': 'https://api.github.com/repos/PROHackerr/OnlineClassesBot/contents/{+path}',\n",
       "  'compare_url': 'https://api.github.com/repos/PROHackerr/OnlineClassesBot/compare/{base}...{head}',\n",
       "  'merges_url': 'https://api.github.com/repos/PROHackerr/OnlineClassesBot/merges',\n",
       "  'archive_url': 'https://api.github.com/repos/PROHackerr/OnlineClassesBot/{archive_format}{/ref}',\n",
       "  'downloads_url': 'https://api.github.com/repos/PROHackerr/OnlineClassesBot/downloads',\n",
       "  'issues_url': 'https://api.github.com/repos/PROHackerr/OnlineClassesBot/issues{/number}',\n",
       "  'pulls_url': 'https://api.github.com/repos/PROHackerr/OnlineClassesBot/pulls{/number}',\n",
       "  'milestones_url': 'https://api.github.com/repos/PROHackerr/OnlineClassesBot/milestones{/number}',\n",
       "  'notifications_url': 'https://api.github.com/repos/PROHackerr/OnlineClassesBot/notifications{?since,all,participating}',\n",
       "  'labels_url': 'https://api.github.com/repos/PROHackerr/OnlineClassesBot/labels{/name}',\n",
       "  'releases_url': 'https://api.github.com/repos/PROHackerr/OnlineClassesBot/releases{/id}',\n",
       "  'deployments_url': 'https://api.github.com/repos/PROHackerr/OnlineClassesBot/deployments',\n",
       "  'created_at': '2021-02-12T09:59:59Z',\n",
       "  'updated_at': '2021-02-07T11:00:08Z',\n",
       "  'pushed_at': '2021-01-29T10:46:37Z',\n",
       "  'git_url': 'git://github.com/PROHackerr/OnlineClassesBot.git',\n",
       "  'ssh_url': 'git@github.com:PROHackerr/OnlineClassesBot.git',\n",
       "  'clone_url': 'https://github.com/PROHackerr/OnlineClassesBot.git',\n",
       "  'svn_url': 'https://github.com/PROHackerr/OnlineClassesBot',\n",
       "  'homepage': '',\n",
       "  'size': 5444,\n",
       "  'stargazers_count': 0,\n",
       "  'watchers_count': 0,\n",
       "  'language': None,\n",
       "  'has_issues': False,\n",
       "  'has_projects': True,\n",
       "  'has_downloads': True,\n",
       "  'has_wiki': True,\n",
       "  'has_pages': False,\n",
       "  'forks_count': 0,\n",
       "  'mirror_url': None,\n",
       "  'archived': False,\n",
       "  'disabled': False,\n",
       "  'open_issues_count': 0,\n",
       "  'license': None,\n",
       "  'forks': 0,\n",
       "  'open_issues': 0,\n",
       "  'watchers': 0,\n",
       "  'default_branch': 'main',\n",
       "  'public': True}}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = lines[0]\n",
    "\n",
    "json.loads(line)['payload']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " def get_2nd_level_keys(line):\n",
    "        d = json.loads(line)\n",
    "        n = 0\n",
    "        for v in d.values():\n",
    "            if isinstance(v, dict):\n",
    "                n += len(v.keys())\n",
    "            else:\n",
    "                n += 1\n",
    "        return n\n",
    "    \n",
    "get_2nd_level_keys(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'nlines': 120737,\n",
       "  'avg_line_length': 4567.872781334637,\n",
       "  'path': 'data/2021-02-12-10.json',\n",
       "  'avg_nkeys': 7.352162137538617,\n",
       "  'min_nkeys': 7,\n",
       "  'max_nkeys': 8,\n",
       "  'nuniq_1st_level': {7: 0.647837862461383, 8: 0.35216213753861697}},\n",
       " {'nlines': 1057,\n",
       "  'avg_line_length': 881.2147587511826,\n",
       "  'path': 'data/2011-02-12-10.json',\n",
       "  'avg_nkeys': 7.114474929044466,\n",
       "  'min_nkeys': 7,\n",
       "  'max_nkeys': 8,\n",
       "  'nuniq_1st_level': {7: 0.8855250709555346, 8: 0.11447492904446546}}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "rows.append(get_global_stats('data/2021-02-12-10.json'))\n",
    "rows.append(get_global_stats('data/2011-02-12-10.json'))\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
