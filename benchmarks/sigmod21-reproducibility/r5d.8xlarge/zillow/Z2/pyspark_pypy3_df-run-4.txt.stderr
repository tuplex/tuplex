21/03/23 21:30:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/03/23 21:30:19 INFO SparkContext: Running Spark version 2.4.7
21/03/23 21:30:19 INFO SparkContext: Submitted application: read csv
21/03/23 21:30:19 INFO SecurityManager: Changing view acls to: root
21/03/23 21:30:19 INFO SecurityManager: Changing modify acls to: root
21/03/23 21:30:19 INFO SecurityManager: Changing view acls groups to: 
21/03/23 21:30:19 INFO SecurityManager: Changing modify acls groups to: 
21/03/23 21:30:19 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
21/03/23 21:30:19 INFO Utils: Successfully started service 'sparkDriver' on port 43403.
21/03/23 21:30:19 INFO SparkEnv: Registering MapOutputTracker
21/03/23 21:30:19 INFO SparkEnv: Registering BlockManagerMaster
21/03/23 21:30:19 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/23 21:30:19 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/23 21:30:19 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-51acb72e-301e-41f0-a523-6de24c81afde
21/03/23 21:30:19 INFO MemoryStore: MemoryStore started with capacity 53.2 GB
21/03/23 21:30:19 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/23 21:30:19 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/23 21:30:19 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://4e1bb76d17c5:4040
21/03/23 21:30:20 INFO Executor: Starting executor ID driver on host localhost
21/03/23 21:30:20 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36077.
21/03/23 21:30:20 INFO NettyBlockTransferService: Server created on 4e1bb76d17c5:36077
21/03/23 21:30:20 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/23 21:30:20 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 4e1bb76d17c5, 36077, None)
21/03/23 21:30:20 INFO BlockManagerMasterEndpoint: Registering block manager 4e1bb76d17c5:36077 with 53.2 GB RAM, BlockManagerId(driver, 4e1bb76d17c5, 36077, None)
21/03/23 21:30:20 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 4e1bb76d17c5, 36077, None)
21/03/23 21:30:20 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 4e1bb76d17c5, 36077, None)
21/03/23 21:30:20 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/code/benchmark/zillow/Z2/spark-warehouse').
21/03/23 21:30:20 INFO SharedState: Warehouse path is 'file:/code/benchmark/zillow/Z2/spark-warehouse'.
21/03/23 21:30:20 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/03/23 21:30:20 INFO InMemoryFileIndex: It took 26 ms to list leaf files for 1 paths.
21/03/23 21:30:20 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
21/03/23 21:30:22 INFO FileSourceStrategy: Pruning directories with: 
21/03/23 21:30:22 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
21/03/23 21:30:22 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
21/03/23 21:30:22 INFO FileSourceScanExec: Pushed Filters: 
21/03/23 21:30:22 INFO CodeGenerator: Code generated in 164.619378 ms
21/03/23 21:30:22 INFO CodeGenerator: Code generated in 13.418043 ms
21/03/23 21:30:22 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 360.3 KB, free 53.2 GB)
21/03/23 21:30:22 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.4 KB, free 53.2 GB)
21/03/23 21:30:22 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 4e1bb76d17c5:36077 (size: 23.4 KB, free: 53.2 GB)
21/03/23 21:30:22 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
21/03/23 21:30:22 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
21/03/23 21:30:22 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
21/03/23 21:30:22 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/23 21:30:22 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
21/03/23 21:30:22 INFO DAGScheduler: Parents of final stage: List()
21/03/23 21:30:22 INFO DAGScheduler: Missing parents: List()
21/03/23 21:30:22 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/23 21:30:22 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 8.9 KB, free 53.2 GB)
21/03/23 21:30:22 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.6 KB, free 53.2 GB)
21/03/23 21:30:22 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 4e1bb76d17c5:36077 (size: 4.6 KB, free: 53.2 GB)
21/03/23 21:30:22 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1184
21/03/23 21:30:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/23 21:30:22 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/03/23 21:30:22 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:22 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/03/23 21:30:23 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 0-134217728, partition values: [empty row]
21/03/23 21:30:23 INFO CodeGenerator: Code generated in 7.607121 ms
21/03/23 21:30:23 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1362 bytes result sent to driver
21/03/23 21:30:23 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 100 ms on localhost (executor driver) (1/1)
21/03/23 21:30:23 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/03/23 21:30:23 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 0.165 s
21/03/23 21:30:23 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 0.197414 s
21/03/23 21:30:23 INFO FileSourceStrategy: Pruning directories with: 
21/03/23 21:30:23 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/23 21:30:23 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
21/03/23 21:30:23 INFO FileSourceScanExec: Pushed Filters: 
21/03/23 21:30:23 INFO CodeGenerator: Code generated in 6.030848 ms
21/03/23 21:30:23 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 360.3 KB, free 53.2 GB)
21/03/23 21:30:23 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 23.4 KB, free 53.2 GB)
21/03/23 21:30:23 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 4e1bb76d17c5:36077 (size: 23.4 KB, free: 53.2 GB)
21/03/23 21:30:23 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
21/03/23 21:30:23 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
21/03/23 21:30:23 INFO FileSourceStrategy: Pruning directories with: 
21/03/23 21:30:23 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/23 21:30:23 INFO FileSourceStrategy: Output Data Schema: struct<title: string, address: string, city: string, state: string, postal_code: string ... 8 more fields>
21/03/23 21:30:23 INFO FileSourceScanExec: Pushed Filters: 
21/03/23 21:30:23 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:23 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:23 INFO CodeGenerator: Code generated in 16.790686 ms
21/03/23 21:30:23 INFO CodeGenerator: Code generated in 13.297429 ms
21/03/23 21:30:23 INFO CodeGenerator: Code generated in 11.620359 ms
21/03/23 21:30:23 INFO CodeGenerator: Code generated in 15.62463 ms
21/03/23 21:30:23 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 360.1 KB, free 53.2 GB)
21/03/23 21:30:23 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 23.4 KB, free 53.2 GB)
21/03/23 21:30:23 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 4e1bb76d17c5:36077 (size: 23.4 KB, free: 53.2 GB)
21/03/23 21:30:23 INFO SparkContext: Created broadcast 3 from csv at NativeMethodAccessorImpl.java:0
21/03/23 21:30:23 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
21/03/23 21:30:23 INFO ContextCleaner: Cleaned accumulator 18
21/03/23 21:30:23 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 4e1bb76d17c5:36077 in memory (size: 4.6 KB, free: 53.2 GB)
21/03/23 21:30:23 INFO ContextCleaner: Cleaned accumulator 24
21/03/23 21:30:23 INFO ContextCleaner: Cleaned accumulator 21
21/03/23 21:30:23 INFO ContextCleaner: Cleaned accumulator 23
21/03/23 21:30:23 INFO ContextCleaner: Cleaned accumulator 27
21/03/23 21:30:23 INFO ContextCleaner: Cleaned accumulator 11
21/03/23 21:30:23 INFO ContextCleaner: Cleaned accumulator 12
21/03/23 21:30:23 INFO ContextCleaner: Cleaned accumulator 25
21/03/23 21:30:23 INFO ContextCleaner: Cleaned accumulator 28
21/03/23 21:30:23 INFO ContextCleaner: Cleaned accumulator 29
21/03/23 21:30:23 INFO ContextCleaner: Cleaned accumulator 16
21/03/23 21:30:23 INFO ContextCleaner: Cleaned accumulator 30
21/03/23 21:30:23 INFO ContextCleaner: Cleaned accumulator 10
21/03/23 21:30:23 INFO ContextCleaner: Cleaned accumulator 17
21/03/23 21:30:23 INFO ContextCleaner: Cleaned accumulator 26
21/03/23 21:30:23 INFO ContextCleaner: Cleaned accumulator 9
21/03/23 21:30:23 INFO ContextCleaner: Cleaned accumulator 14
21/03/23 21:30:23 INFO ContextCleaner: Cleaned accumulator 31
21/03/23 21:30:23 INFO ContextCleaner: Cleaned accumulator 13
21/03/23 21:30:23 INFO ContextCleaner: Cleaned accumulator 15
21/03/23 21:30:23 INFO ContextCleaner: Cleaned accumulator 22
21/03/23 21:30:23 INFO ContextCleaner: Cleaned accumulator 8
21/03/23 21:30:23 INFO ContextCleaner: Cleaned accumulator 20
21/03/23 21:30:23 INFO ContextCleaner: Cleaned accumulator 19
21/03/23 21:30:23 INFO ContextCleaner: Cleaned accumulator 7
21/03/23 21:30:23 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
21/03/23 21:30:23 INFO DAGScheduler: Got job 1 (csv at NativeMethodAccessorImpl.java:0) with 81 output partitions
21/03/23 21:30:23 INFO DAGScheduler: Final stage: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0)
21/03/23 21:30:23 INFO DAGScheduler: Parents of final stage: List()
21/03/23 21:30:23 INFO DAGScheduler: Missing parents: List()
21/03/23 21:30:23 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[23] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/23 21:30:24 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 188.4 KB, free 53.2 GB)
21/03/23 21:30:24 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 66.1 KB, free 53.2 GB)
21/03/23 21:30:24 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 4e1bb76d17c5:36077 (size: 66.1 KB, free: 53.2 GB)
21/03/23 21:30:24 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1184
21/03/23 21:30:24 INFO DAGScheduler: Submitting 81 missing tasks from ResultStage 1 (MapPartitionsRDD[23] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
21/03/23 21:30:24 INFO TaskSchedulerImpl: Adding task set 1.0 with 81 tasks
21/03/23 21:30:24 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:24 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 1, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:24 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3, localhost, executor driver, partition 2, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:24 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4, localhost, executor driver, partition 3, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:24 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5, localhost, executor driver, partition 4, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:24 INFO TaskSetManager: Starting task 5.0 in stage 1.0 (TID 6, localhost, executor driver, partition 5, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:24 INFO TaskSetManager: Starting task 6.0 in stage 1.0 (TID 7, localhost, executor driver, partition 6, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:24 INFO TaskSetManager: Starting task 7.0 in stage 1.0 (TID 8, localhost, executor driver, partition 7, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:24 INFO TaskSetManager: Starting task 8.0 in stage 1.0 (TID 9, localhost, executor driver, partition 8, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:24 INFO TaskSetManager: Starting task 9.0 in stage 1.0 (TID 10, localhost, executor driver, partition 9, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:24 INFO TaskSetManager: Starting task 10.0 in stage 1.0 (TID 11, localhost, executor driver, partition 10, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:24 INFO TaskSetManager: Starting task 11.0 in stage 1.0 (TID 12, localhost, executor driver, partition 11, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:24 INFO TaskSetManager: Starting task 12.0 in stage 1.0 (TID 13, localhost, executor driver, partition 12, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:24 INFO TaskSetManager: Starting task 13.0 in stage 1.0 (TID 14, localhost, executor driver, partition 13, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:24 INFO TaskSetManager: Starting task 14.0 in stage 1.0 (TID 15, localhost, executor driver, partition 14, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:24 INFO TaskSetManager: Starting task 15.0 in stage 1.0 (TID 16, localhost, executor driver, partition 15, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:24 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/03/23 21:30:24 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
21/03/23 21:30:24 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
21/03/23 21:30:24 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)
21/03/23 21:30:24 INFO Executor: Running task 4.0 in stage 1.0 (TID 5)
21/03/23 21:30:24 INFO Executor: Running task 5.0 in stage 1.0 (TID 6)
21/03/23 21:30:24 INFO Executor: Running task 6.0 in stage 1.0 (TID 7)
21/03/23 21:30:24 INFO Executor: Running task 7.0 in stage 1.0 (TID 8)
21/03/23 21:30:24 INFO Executor: Running task 8.0 in stage 1.0 (TID 9)
21/03/23 21:30:24 INFO Executor: Running task 9.0 in stage 1.0 (TID 10)
21/03/23 21:30:24 INFO Executor: Running task 10.0 in stage 1.0 (TID 11)
21/03/23 21:30:24 INFO Executor: Running task 11.0 in stage 1.0 (TID 12)
21/03/23 21:30:24 INFO Executor: Running task 12.0 in stage 1.0 (TID 13)
21/03/23 21:30:24 INFO Executor: Running task 15.0 in stage 1.0 (TID 16)
21/03/23 21:30:24 INFO Executor: Running task 14.0 in stage 1.0 (TID 15)
21/03/23 21:30:24 INFO Executor: Running task 13.0 in stage 1.0 (TID 14)
21/03/23 21:30:24 INFO CodeGenerator: Code generated in 6.851207 ms
21/03/23 21:30:24 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 0-134217728, partition values: [empty row]
21/03/23 21:30:24 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 2013265920-2147483648, partition values: [empty row]
21/03/23 21:30:24 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 1610612736-1744830464, partition values: [empty row]
21/03/23 21:30:24 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 1476395008-1610612736, partition values: [empty row]
21/03/23 21:30:24 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 268435456-402653184, partition values: [empty row]
21/03/23 21:30:24 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 1744830464-1879048192, partition values: [empty row]
21/03/23 21:30:24 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 805306368-939524096, partition values: [empty row]
21/03/23 21:30:24 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 939524096-1073741824, partition values: [empty row]
21/03/23 21:30:24 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 536870912-671088640, partition values: [empty row]
21/03/23 21:30:24 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 1073741824-1207959552, partition values: [empty row]
21/03/23 21:30:24 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 402653184-536870912, partition values: [empty row]
21/03/23 21:30:24 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 1879048192-2013265920, partition values: [empty row]
21/03/23 21:30:24 INFO CodeGenerator: Code generated in 16.008707 ms
21/03/23 21:30:24 INFO CodeGenerator: Code generated in 18.252662 ms
21/03/23 21:30:24 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 1342177280-1476395008, partition values: [empty row]
21/03/23 21:30:24 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 134217728-268435456, partition values: [empty row]
21/03/23 21:30:24 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 1207959552-1342177280, partition values: [empty row]
21/03/23 21:30:24 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 671088640-805306368, partition values: [empty row]
21/03/23 21:30:24 INFO CodeGenerator: Code generated in 46.166473 ms
21/03/23 21:30:25 INFO CodeGenerator: Code generated in 262.090803 ms
21/03/23 21:30:25 INFO ContextCleaner: Cleaned accumulator 3
21/03/23 21:30:25 INFO ContextCleaner: Cleaned accumulator 4
21/03/23 21:30:25 INFO ContextCleaner: Cleaned accumulator 34
21/03/23 21:30:25 INFO ContextCleaner: Cleaned accumulator 6
21/03/23 21:30:25 INFO ContextCleaner: Cleaned accumulator 32
21/03/23 21:30:25 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 4e1bb76d17c5:36077 in memory (size: 23.4 KB, free: 53.2 GB)
21/03/23 21:30:25 INFO CodeGenerator: Code generated in 20.499259 ms
21/03/23 21:30:25 INFO ContextCleaner: Cleaned accumulator 35
21/03/23 21:30:25 INFO ContextCleaner: Cleaned accumulator 36
21/03/23 21:30:25 INFO ContextCleaner: Cleaned accumulator 2
21/03/23 21:30:25 INFO ContextCleaner: Cleaned accumulator 33
21/03/23 21:30:25 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 4e1bb76d17c5:36077 in memory (size: 23.4 KB, free: 53.2 GB)
21/03/23 21:30:25 INFO CodeGenerator: Code generated in 19.982548 ms
21/03/23 21:30:25 INFO ContextCleaner: Cleaned accumulator 5
21/03/23 21:30:25 INFO ContextCleaner: Cleaned accumulator 1
21/03/23 21:30:25 INFO CodeGenerator: Code generated in 6.707551 ms
21/03/23 21:30:26 INFO CodeGenerator: Code generated in 264.461262 ms
21/03/23 21:30:26 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:26 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:26 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:26 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:26 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:26 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:26 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:26 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:26 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:26 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:26 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:26 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:26 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:26 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:26 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:26 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:26 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:26 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:26 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:26 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:26 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:26 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:26 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:26 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:26 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:26 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:27 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:26 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:27 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:26 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:26 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:33 INFO PythonUDFRunner: Times: total = 9505, boot = 652, init = 594, finish = 8259
21/03/23 21:30:33 INFO PythonUDFRunner: Times: total = 8724, boot = 273, init = 1327, finish = 7124
21/03/23 21:30:34 INFO PythonUDFRunner: Times: total = 8561, boot = 140, init = 2877, finish = 5544
21/03/23 21:30:34 INFO PythonUDFRunner: Times: total = 8258, boot = 385, init = 2864, finish = 5009
21/03/23 21:30:34 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000013_14' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000013
21/03/23 21:30:34 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000013_14: Committed
21/03/23 21:30:34 INFO Executor: Finished task 13.0 in stage 1.0 (TID 14). 3635 bytes result sent to driver
21/03/23 21:30:34 INFO TaskSetManager: Starting task 16.0 in stage 1.0 (TID 17, localhost, executor driver, partition 16, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:34 INFO TaskSetManager: Finished task 13.0 in stage 1.0 (TID 14) in 10345 ms on localhost (executor driver) (1/81)
21/03/23 21:30:34 INFO Executor: Running task 16.0 in stage 1.0 (TID 17)
21/03/23 21:30:34 INFO PythonAccumulatorV2: Connected to AccumulatorServer at host: 127.0.0.1 port: 44867
21/03/23 21:30:34 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 2147483648-2281701376, partition values: [empty row]
21/03/23 21:30:34 INFO PythonUDFRunner: Times: total = 10404, boot = 660, init = 588, finish = 9156
21/03/23 21:30:34 INFO PythonUDFRunner: Times: total = 9702, boot = 104, init = 1618, finish = 7980
21/03/23 21:30:34 INFO PythonUDFRunner: Times: total = 10436, boot = 663, init = 551, finish = 9222
21/03/23 21:30:34 INFO PythonUDFRunner: Times: total = 9624, boot = 518, init = 1127, finish = 7979
21/03/23 21:30:34 INFO PythonUDFRunner: Times: total = 9352, boot = 81, init = 3679, finish = 5592
21/03/23 21:30:34 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:34 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:34 INFO PythonUDFRunner: Times: total = 8938, boot = 81, init = 2489, finish = 6368
21/03/23 21:30:34 INFO PythonUDFRunner: Times: total = 8967, boot = 764, init = 2977, finish = 5226
21/03/23 21:30:34 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000004_5' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000004
21/03/23 21:30:34 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000004_5: Committed
21/03/23 21:30:34 INFO PythonUDFRunner: Times: total = 8664, boot = 562, init = 2398, finish = 5704
21/03/23 21:30:34 INFO Executor: Finished task 4.0 in stage 1.0 (TID 5). 3592 bytes result sent to driver
21/03/23 21:30:34 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000008_9' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000008
21/03/23 21:30:34 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000008_9: Committed
21/03/23 21:30:34 INFO TaskSetManager: Starting task 17.0 in stage 1.0 (TID 18, localhost, executor driver, partition 17, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:34 INFO Executor: Running task 17.0 in stage 1.0 (TID 18)
21/03/23 21:30:34 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 2281701376-2415919104, partition values: [empty row]
21/03/23 21:30:34 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 10961 ms on localhost (executor driver) (2/81)
21/03/23 21:30:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:35 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:35 INFO PythonUDFRunner: Times: total = 10859, boot = 669, init = 548, finish = 9642
21/03/23 21:30:35 INFO PythonUDFRunner: Times: total = 10160, boot = 396, init = 1315, finish = 8449
21/03/23 21:30:35 INFO Executor: Finished task 8.0 in stage 1.0 (TID 9). 3592 bytes result sent to driver
21/03/23 21:30:35 INFO TaskSetManager: Starting task 18.0 in stage 1.0 (TID 19, localhost, executor driver, partition 18, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:35 INFO Executor: Running task 18.0 in stage 1.0 (TID 19)
21/03/23 21:30:35 INFO TaskSetManager: Finished task 8.0 in stage 1.0 (TID 9) in 11077 ms on localhost (executor driver) (3/81)
21/03/23 21:30:35 INFO PythonUDFRunner: Times: total = 9797, boot = 33, init = 2976, finish = 6788
21/03/23 21:30:35 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 2415919104-2550136832, partition values: [empty row]
21/03/23 21:30:35 INFO PythonUDFRunner: Times: total = 9645, boot = 338, init = 3301, finish = 6006
21/03/23 21:30:35 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000014_15' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000014
21/03/23 21:30:35 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000014_15: Committed
21/03/23 21:30:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:35 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:35 INFO PythonUDFRunner: Times: total = 11068, boot = 680, init = 531, finish = 9857
21/03/23 21:30:35 INFO Executor: Finished task 14.0 in stage 1.0 (TID 15). 3592 bytes result sent to driver
21/03/23 21:30:35 INFO TaskSetManager: Starting task 19.0 in stage 1.0 (TID 20, localhost, executor driver, partition 19, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:35 INFO Executor: Running task 19.0 in stage 1.0 (TID 20)
21/03/23 21:30:35 INFO PythonUDFRunner: Times: total = 11101, boot = 634, init = 580, finish = 9887
21/03/23 21:30:35 INFO TaskSetManager: Finished task 14.0 in stage 1.0 (TID 15) in 11273 ms on localhost (executor driver) (4/81)
21/03/23 21:30:35 INFO PythonUDFRunner: Times: total = 10252, boot = 452, init = 1266, finish = 8534
21/03/23 21:30:35 INFO PythonUDFRunner: Times: total = 10317, boot = 12, init = 1720, finish = 8585
21/03/23 21:30:35 INFO PythonUDFRunner: Times: total = 9591, boot = 311, init = 2305, finish = 6975
21/03/23 21:30:35 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 2550136832-2684354560, partition values: [empty row]
21/03/23 21:30:35 INFO PythonUDFRunner: Times: total = 9277, boot = 505, init = 2451, finish = 6321
21/03/23 21:30:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:35 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:35 INFO PythonUDFRunner: Times: total = 10068, boot = 60, init = 2760, finish = 7248
21/03/23 21:30:35 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000001_2' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000001
21/03/23 21:30:35 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000001_2: Committed
21/03/23 21:30:35 INFO PythonUDFRunner: Times: total = 11345, boot = 686, init = 525, finish = 10134
21/03/23 21:30:35 INFO PythonUDFRunner: Times: total = 10630, boot = 422, init = 1339, finish = 8869
21/03/23 21:30:35 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 3635 bytes result sent to driver
21/03/23 21:30:35 INFO TaskSetManager: Starting task 20.0 in stage 1.0 (TID 21, localhost, executor driver, partition 20, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:35 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 11571 ms on localhost (executor driver) (5/81)
21/03/23 21:30:35 INFO Executor: Running task 20.0 in stage 1.0 (TID 21)
21/03/23 21:30:35 INFO PythonUDFRunner: Times: total = 10229, boot = 471, init = 3271, finish = 6487
21/03/23 21:30:35 INFO PythonUDFRunner: Times: total = 9675, boot = 43, init = 2694, finish = 6938
21/03/23 21:30:35 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000011_12' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000011
21/03/23 21:30:35 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000011_12: Committed
21/03/23 21:30:35 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 2684354560-2818572288, partition values: [empty row]
21/03/23 21:30:35 INFO PythonUDFRunner: Times: total = 11469, boot = 649, init = 585, finish = 10235
21/03/23 21:30:35 INFO PythonUDFRunner: Times: total = 10735, boot = 390, init = 1373, finish = 8972
21/03/23 21:30:35 INFO PythonUDFRunner: Times: total = 9687, boot = 809, init = 2572, finish = 6306
21/03/23 21:30:35 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000005_6' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000005
21/03/23 21:30:35 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000005_6: Committed
21/03/23 21:30:35 INFO PythonUDFRunner: Times: total = 11566, boot = 643, init = 587, finish = 10336
21/03/23 21:30:35 INFO PythonUDFRunner: Times: total = 10731, boot = 268, init = 1319, finish = 9144
21/03/23 21:30:35 INFO PythonUDFRunner: Times: total = 10458, boot = 43, init = 2966, finish = 7449
21/03/23 21:30:35 INFO PythonUDFRunner: Times: total = 11596, boot = 672, init = 598, finish = 10326
21/03/23 21:30:35 INFO PythonUDFRunner: Times: total = 10872, boot = 402, init = 1383, finish = 9087
21/03/23 21:30:35 INFO PythonUDFRunner: Times: total = 10108, boot = 742, init = 2309, finish = 7057
21/03/23 21:30:35 INFO PythonUDFRunner: Times: total = 10466, boot = 459, init = 3316, finish = 6691
21/03/23 21:30:35 INFO PythonUDFRunner: Times: total = 10506, boot = 145, init = 2344, finish = 8017
21/03/23 21:30:35 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000012_13' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000012
21/03/23 21:30:35 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000012_13: Committed
21/03/23 21:30:35 INFO Executor: Finished task 11.0 in stage 1.0 (TID 12). 3592 bytes result sent to driver
21/03/23 21:30:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:35 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:35 INFO PythonUDFRunner: Times: total = 9836, boot = 619, init = 2685, finish = 6532
21/03/23 21:30:35 INFO PythonUDFRunner: Times: total = 10397, boot = 232, init = 2752, finish = 7413
21/03/23 21:30:35 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000000_1' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000000
21/03/23 21:30:35 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000010_11' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000010
21/03/23 21:30:35 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000000_1: Committed
21/03/23 21:30:35 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000010_11: Committed
21/03/23 21:30:35 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 3592 bytes result sent to driver
21/03/23 21:30:35 INFO TaskSetManager: Starting task 21.0 in stage 1.0 (TID 22, localhost, executor driver, partition 21, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:35 INFO Executor: Running task 21.0 in stage 1.0 (TID 22)
21/03/23 21:30:35 INFO TaskSetManager: Starting task 22.0 in stage 1.0 (TID 23, localhost, executor driver, partition 22, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:35 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 11962 ms on localhost (executor driver) (6/81)
21/03/23 21:30:35 INFO Executor: Running task 22.0 in stage 1.0 (TID 23)
21/03/23 21:30:35 INFO TaskSetManager: Finished task 11.0 in stage 1.0 (TID 12) in 11963 ms on localhost (executor driver) (7/81)
21/03/23 21:30:35 INFO Executor: Finished task 5.0 in stage 1.0 (TID 6). 3592 bytes result sent to driver
21/03/23 21:30:35 INFO Executor: Finished task 10.0 in stage 1.0 (TID 11). 3635 bytes result sent to driver
21/03/23 21:30:35 INFO TaskSetManager: Starting task 23.0 in stage 1.0 (TID 24, localhost, executor driver, partition 23, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:35 INFO Executor: Running task 23.0 in stage 1.0 (TID 24)
21/03/23 21:30:35 INFO TaskSetManager: Starting task 24.0 in stage 1.0 (TID 25, localhost, executor driver, partition 24, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:35 INFO TaskSetManager: Finished task 5.0 in stage 1.0 (TID 6) in 11965 ms on localhost (executor driver) (8/81)
21/03/23 21:30:35 INFO Executor: Running task 24.0 in stage 1.0 (TID 25)
21/03/23 21:30:35 INFO TaskSetManager: Finished task 10.0 in stage 1.0 (TID 11) in 11964 ms on localhost (executor driver) (9/81)
21/03/23 21:30:35 INFO Executor: Finished task 12.0 in stage 1.0 (TID 13). 3592 bytes result sent to driver
21/03/23 21:30:35 INFO TaskSetManager: Starting task 25.0 in stage 1.0 (TID 26, localhost, executor driver, partition 25, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:35 INFO TaskSetManager: Finished task 12.0 in stage 1.0 (TID 13) in 11970 ms on localhost (executor driver) (10/81)
21/03/23 21:30:35 INFO Executor: Running task 25.0 in stage 1.0 (TID 26)
21/03/23 21:30:35 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 2818572288-2952790016, partition values: [empty row]
21/03/23 21:30:36 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 3355443200-3489660928, partition values: [empty row]
21/03/23 21:30:36 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 2952790016-3087007744, partition values: [empty row]
21/03/23 21:30:36 INFO PythonUDFRunner: Times: total = 11940, boot = 646, init = 641, finish = 10653
21/03/23 21:30:36 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 3087007744-3221225472, partition values: [empty row]
21/03/23 21:30:36 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 3221225472-3355443200, partition values: [empty row]
21/03/23 21:30:36 INFO PythonUDFRunner: Times: total = 11933, boot = 658, init = 558, finish = 10717
21/03/23 21:30:36 INFO PythonUDFRunner: Times: total = 11143, boot = 260, init = 1401, finish = 9482
21/03/23 21:30:36 INFO PythonUDFRunner: Times: total = 12034, boot = 655, init = 557, finish = 10822
21/03/23 21:30:36 INFO PythonUDFRunner: Times: total = 11104, boot = 264, init = 1374, finish = 9466
21/03/23 21:30:36 INFO PythonUDFRunner: Times: total = 11179, boot = 491, init = 1082, finish = 9606
21/03/23 21:30:36 INFO PythonUDFRunner: Times: total = 10918, boot = 119, init = 3862, finish = 6937
21/03/23 21:30:36 INFO PythonUDFRunner: Times: total = 12147, boot = 684, init = 532, finish = 10931
21/03/23 21:30:36 INFO PythonUDFRunner: Times: total = 11416, boot = 419, init = 1384, finish = 9613
21/03/23 21:30:36 INFO PythonUDFRunner: Times: total = 11031, boot = 487, init = 2499, finish = 8045
21/03/23 21:30:36 INFO PythonUDFRunner: Times: total = 12209, boot = 666, init = 552, finish = 10991
21/03/23 21:30:36 INFO PythonUDFRunner: Times: total = 10483, boot = 187, init = 3313, finish = 6983
21/03/23 21:30:36 INFO PythonUDFRunner: Times: total = 10882, boot = 134, init = 3636, finish = 7112
21/03/23 21:30:36 INFO PythonUDFRunner: Times: total = 11401, boot = 17, init = 1655, finish = 9729
21/03/23 21:30:36 INFO PythonUDFRunner: Times: total = 10690, boot = 593, init = 3054, finish = 7043
21/03/23 21:30:36 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000007_8' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000007
21/03/23 21:30:36 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000007_8: Committed
21/03/23 21:30:36 INFO PythonUDFRunner: Times: total = 10482, boot = 332, init = 3763, finish = 6387
21/03/23 21:30:36 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000015_16' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000015
21/03/23 21:30:36 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000015_16: Committed
21/03/23 21:30:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:36 INFO PythonUDFRunner: Times: total = 10415, boot = 722, init = 2370, finish = 7323
21/03/23 21:30:36 INFO PythonUDFRunner: Times: total = 11181, boot = 48, init = 3720, finish = 7413
21/03/23 21:30:36 INFO PythonUDFRunner: Times: total = 10440, boot = 759, init = 3138, finish = 6543
21/03/23 21:30:36 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000006_7' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000006
21/03/23 21:30:36 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000006_7: Committed
21/03/23 21:30:36 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000009_10' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000009
21/03/23 21:30:36 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000009_10: Committed
21/03/23 21:30:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:36 INFO PythonUDFRunner: Times: total = 10793, boot = 781, init = 2961, finish = 7051
21/03/23 21:30:36 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000003_4' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000003
21/03/23 21:30:36 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000003_4: Committed
21/03/23 21:30:36 INFO PythonUDFRunner: Times: total = 12428, boot = 639, init = 598, finish = 11191
21/03/23 21:30:36 INFO PythonUDFRunner: Times: total = 11573, boot = 496, init = 942, finish = 10135
21/03/23 21:30:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:36 INFO PythonUDFRunner: Times: total = 10925, boot = 345, init = 2063, finish = 8517
21/03/23 21:30:36 INFO PythonUDFRunner: Times: total = 10325, boot = 125, init = 2291, finish = 7909
21/03/23 21:30:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:36 INFO Executor: Finished task 7.0 in stage 1.0 (TID 8). 3592 bytes result sent to driver
21/03/23 21:30:36 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000002_3' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000002
21/03/23 21:30:36 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000002_3: Committed
21/03/23 21:30:36 INFO TaskSetManager: Starting task 26.0 in stage 1.0 (TID 27, localhost, executor driver, partition 26, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:36 INFO Executor: Running task 26.0 in stage 1.0 (TID 27)
21/03/23 21:30:36 INFO TaskSetManager: Finished task 7.0 in stage 1.0 (TID 8) in 12792 ms on localhost (executor driver) (11/81)
21/03/23 21:30:36 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 3592 bytes result sent to driver
21/03/23 21:30:36 INFO Executor: Finished task 6.0 in stage 1.0 (TID 7). 3592 bytes result sent to driver
21/03/23 21:30:36 INFO TaskSetManager: Starting task 27.0 in stage 1.0 (TID 28, localhost, executor driver, partition 27, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:36 INFO Executor: Running task 27.0 in stage 1.0 (TID 28)
21/03/23 21:30:36 INFO TaskSetManager: Starting task 28.0 in stage 1.0 (TID 29, localhost, executor driver, partition 28, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:36 INFO Executor: Running task 28.0 in stage 1.0 (TID 29)
21/03/23 21:30:36 INFO Executor: Finished task 15.0 in stage 1.0 (TID 16). 3592 bytes result sent to driver
21/03/23 21:30:36 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 12834 ms on localhost (executor driver) (12/81)
21/03/23 21:30:36 INFO TaskSetManager: Finished task 6.0 in stage 1.0 (TID 7) in 12833 ms on localhost (executor driver) (13/81)
21/03/23 21:30:36 INFO Executor: Finished task 9.0 in stage 1.0 (TID 10). 3592 bytes result sent to driver
21/03/23 21:30:36 INFO TaskSetManager: Starting task 29.0 in stage 1.0 (TID 30, localhost, executor driver, partition 29, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:36 INFO Executor: Running task 29.0 in stage 1.0 (TID 30)
21/03/23 21:30:36 INFO TaskSetManager: Starting task 30.0 in stage 1.0 (TID 31, localhost, executor driver, partition 30, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:36 INFO TaskSetManager: Finished task 15.0 in stage 1.0 (TID 16) in 12836 ms on localhost (executor driver) (14/81)
21/03/23 21:30:36 INFO TaskSetManager: Finished task 9.0 in stage 1.0 (TID 10) in 12837 ms on localhost (executor driver) (15/81)
21/03/23 21:30:36 INFO Executor: Running task 30.0 in stage 1.0 (TID 31)
21/03/23 21:30:36 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 3489660928-3623878656, partition values: [empty row]
21/03/23 21:30:36 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 3623878656-3758096384, partition values: [empty row]
21/03/23 21:30:36 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 3758096384-3892314112, partition values: [empty row]
21/03/23 21:30:36 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 4026531840-4160749568, partition values: [empty row]
21/03/23 21:30:36 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 3892314112-4026531840, partition values: [empty row]
21/03/23 21:30:37 INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 3592 bytes result sent to driver
21/03/23 21:30:37 INFO TaskSetManager: Starting task 31.0 in stage 1.0 (TID 32, localhost, executor driver, partition 31, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:37 INFO Executor: Running task 31.0 in stage 1.0 (TID 32)
21/03/23 21:30:37 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 13036 ms on localhost (executor driver) (16/81)
21/03/23 21:30:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:37 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 4160749568-4294967296, partition values: [empty row]
21/03/23 21:30:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:42 INFO PythonUDFRunner: Times: total = 6182, boot = -436, init = 524, finish = 6094
21/03/23 21:30:42 INFO PythonUDFRunner: Times: total = 6139, boot = -441, init = 892, finish = 5688
21/03/23 21:30:42 INFO PythonUDFRunner: Times: total = 5940, boot = -590, init = 2103, finish = 4427
21/03/23 21:30:42 INFO PythonUDFRunner: Times: total = 7904, boot = -753, init = 907, finish = 7750
21/03/23 21:30:42 INFO PythonUDFRunner: Times: total = 7873, boot = -762, init = 1211, finish = 7424
21/03/23 21:30:42 INFO PythonUDFRunner: Times: total = 5958, boot = -619, init = 2581, finish = 3996
21/03/23 21:30:42 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000025_26' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000025
21/03/23 21:30:42 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000025_26: Committed
21/03/23 21:30:42 INFO PythonUDFRunner: Times: total = 7901, boot = -752, init = 2281, finish = 6372
21/03/23 21:30:42 INFO Executor: Finished task 25.0 in stage 1.0 (TID 26). 3592 bytes result sent to driver
21/03/23 21:30:42 INFO TaskSetManager: Starting task 32.0 in stage 1.0 (TID 33, localhost, executor driver, partition 32, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:42 INFO PythonUDFRunner: Times: total = 7917, boot = -614, init = 2338, finish = 6193
21/03/23 21:30:42 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000016_17' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000016
21/03/23 21:30:42 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000016_17: Committed
21/03/23 21:30:42 INFO TaskSetManager: Finished task 25.0 in stage 1.0 (TID 26) in 6694 ms on localhost (executor driver) (17/81)
21/03/23 21:30:42 INFO Executor: Running task 32.0 in stage 1.0 (TID 33)
21/03/23 21:30:42 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 4294967296-4429185024, partition values: [empty row]
21/03/23 21:30:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:42 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:42 INFO Executor: Finished task 16.0 in stage 1.0 (TID 17). 3592 bytes result sent to driver
21/03/23 21:30:42 INFO TaskSetManager: Starting task 33.0 in stage 1.0 (TID 34, localhost, executor driver, partition 33, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:42 INFO Executor: Running task 33.0 in stage 1.0 (TID 34)
21/03/23 21:30:42 INFO TaskSetManager: Finished task 16.0 in stage 1.0 (TID 17) in 8498 ms on localhost (executor driver) (18/81)
21/03/23 21:30:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:42 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:42 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 4429185024-4563402752, partition values: [empty row]
21/03/23 21:30:43 INFO PythonUDFRunner: Times: total = 6969, boot = -419, init = 557, finish = 6831
21/03/23 21:30:43 INFO PythonUDFRunner: Times: total = 7963, boot = -383, init = 454, finish = 7892
21/03/23 21:30:43 INFO PythonUDFRunner: Times: total = 6968, boot = -357, init = 931, finish = 6394
21/03/23 21:30:43 INFO PythonUDFRunner: Times: total = 6769, boot = -531, init = 1713, finish = 5587
21/03/23 21:30:43 INFO PythonUDFRunner: Times: total = 7931, boot = -373, init = 851, finish = 7453
21/03/23 21:30:43 INFO PythonUDFRunner: Times: total = 8002, boot = -422, init = 2312, finish = 6112
21/03/23 21:30:43 INFO PythonUDFRunner: Times: total = 6782, boot = -568, init = 2129, finish = 5221
21/03/23 21:30:43 INFO PythonUDFRunner: Times: total = 8088, boot = -363, init = 2431, finish = 6020
21/03/23 21:30:43 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000018_19' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000018
21/03/23 21:30:43 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000018_19: Committed
21/03/23 21:30:43 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000022_23' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000022
21/03/23 21:30:43 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000022_23: Committed
21/03/23 21:30:43 INFO PythonUDFRunner: Times: total = 7715, boot = -301, init = 339, finish = 7677
21/03/23 21:30:43 INFO Executor: Finished task 18.0 in stage 1.0 (TID 19). 3592 bytes result sent to driver
21/03/23 21:30:43 INFO Executor: Finished task 22.0 in stage 1.0 (TID 23). 3635 bytes result sent to driver
21/03/23 21:30:43 INFO PythonUDFRunner: Times: total = 7769, boot = -277, init = 746, finish = 7300
21/03/23 21:30:43 INFO TaskSetManager: Starting task 34.0 in stage 1.0 (TID 35, localhost, executor driver, partition 34, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:43 INFO TaskSetManager: Starting task 35.0 in stage 1.0 (TID 36, localhost, executor driver, partition 35, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:43 INFO Executor: Running task 35.0 in stage 1.0 (TID 36)
21/03/23 21:30:43 INFO Executor: Running task 34.0 in stage 1.0 (TID 35)
21/03/23 21:30:43 INFO PythonUDFRunner: Times: total = 7385, boot = -567, init = 762, finish = 7190
21/03/23 21:30:43 INFO TaskSetManager: Finished task 22.0 in stage 1.0 (TID 23) in 7483 ms on localhost (executor driver) (19/81)
21/03/23 21:30:43 INFO TaskSetManager: Finished task 18.0 in stage 1.0 (TID 19) in 8376 ms on localhost (executor driver) (20/81)
21/03/23 21:30:43 INFO PythonUDFRunner: Times: total = 7313, boot = -446, init = 1031, finish = 6728
21/03/23 21:30:43 INFO PythonUDFRunner: Times: total = 7794, boot = -366, init = 2151, finish = 6009
21/03/23 21:30:43 INFO PythonUDFRunner: Times: total = 7634, boot = -511, init = 2629, finish = 5516
21/03/23 21:30:43 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000020_21' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000020
21/03/23 21:30:43 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000020_21: Committed
21/03/23 21:30:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:43 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:43 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 4563402752-4697620480, partition values: [empty row]
21/03/23 21:30:43 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 4697620480-4831838208, partition values: [empty row]
21/03/23 21:30:43 INFO PythonUDFRunner: Times: total = 7143, boot = -558, init = 2536, finish = 5165
21/03/23 21:30:43 INFO Executor: Finished task 20.0 in stage 1.0 (TID 21). 3635 bytes result sent to driver
21/03/23 21:30:43 INFO PythonUDFRunner: Times: total = 8361, boot = -186, init = 361, finish = 8186
21/03/23 21:30:43 INFO TaskSetManager: Starting task 36.0 in stage 1.0 (TID 37, localhost, executor driver, partition 36, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:43 INFO Executor: Running task 36.0 in stage 1.0 (TID 37)
21/03/23 21:30:43 INFO TaskSetManager: Finished task 20.0 in stage 1.0 (TID 21) in 8115 ms on localhost (executor driver) (21/81)
21/03/23 21:30:43 INFO PythonUDFRunner: Times: total = 8335, boot = -245, init = 848, finish = 7732
21/03/23 21:30:43 INFO PythonUDFRunner: Times: total = 8371, boot = -195, init = 1652, finish = 6914
21/03/23 21:30:43 INFO PythonUDFRunner: Times: total = 7087, boot = -596, init = 2606, finish = 5077
21/03/23 21:30:43 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000024_25' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000024
21/03/23 21:30:43 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000024_25: Committed
21/03/23 21:30:43 INFO Executor: Finished task 24.0 in stage 1.0 (TID 25). 3592 bytes result sent to driver
21/03/23 21:30:43 INFO TaskSetManager: Starting task 37.0 in stage 1.0 (TID 38, localhost, executor driver, partition 37, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:43 INFO TaskSetManager: Finished task 24.0 in stage 1.0 (TID 25) in 7808 ms on localhost (executor driver) (22/81)
21/03/23 21:30:43 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 4831838208-4966055936, partition values: [empty row]
21/03/23 21:30:43 INFO PythonUDFRunner: Times: total = 8368, boot = -230, init = 1773, finish = 6825
21/03/23 21:30:43 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000019_20' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000019
21/03/23 21:30:43 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000019_20: Committed
21/03/23 21:30:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:43 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:43 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:43 INFO Executor: Running task 37.0 in stage 1.0 (TID 38)
21/03/23 21:30:43 INFO Executor: Finished task 19.0 in stage 1.0 (TID 20). 3592 bytes result sent to driver
21/03/23 21:30:44 INFO TaskSetManager: Starting task 38.0 in stage 1.0 (TID 39, localhost, executor driver, partition 38, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:44 INFO Executor: Running task 38.0 in stage 1.0 (TID 39)
21/03/23 21:30:44 INFO TaskSetManager: Finished task 19.0 in stage 1.0 (TID 20) in 8733 ms on localhost (executor driver) (23/81)
21/03/23 21:30:44 INFO PythonUDFRunner: Times: total = 9062, boot = -272, init = 459, finish = 8875
21/03/23 21:30:44 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 5100273664-5234491392, partition values: [empty row]
21/03/23 21:30:44 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 4966055936-5100273664, partition values: [empty row]
21/03/23 21:30:44 INFO PythonUDFRunner: Times: total = 8095, boot = -534, init = 761, finish = 7868
21/03/23 21:30:44 INFO PythonUDFRunner: Times: total = 9064, boot = -299, init = 916, finish = 8447
21/03/23 21:30:44 INFO PythonUDFRunner: Times: total = 7691, boot = -544, init = 922, finish = 7313
21/03/23 21:30:44 INFO PythonUDFRunner: Times: total = 9140, boot = -317, init = 1961, finish = 7496
21/03/23 21:30:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:44 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:44 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:44 INFO PythonUDFRunner: Times: total = 7619, boot = -661, init = 2630, finish = 5650
21/03/23 21:30:44 INFO PythonUDFRunner: Times: total = 7415, boot = -707, init = 906, finish = 7216
21/03/23 21:30:44 INFO PythonUDFRunner: Times: total = 7582, boot = -689, init = 2756, finish = 5515
21/03/23 21:30:44 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000023_24' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000023
21/03/23 21:30:44 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000023_24: Committed
21/03/23 21:30:44 INFO PythonUDFRunner: Times: total = 7253, boot = -623, init = 1172, finish = 6704
21/03/23 21:30:44 INFO PythonUDFRunner: Times: total = 7298, boot = -847, init = 2228, finish = 5917
21/03/23 21:30:44 INFO PythonUDFRunner: Times: total = 9117, boot = -316, init = 2167, finish = 7266
21/03/23 21:30:44 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000017_18' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000017
21/03/23 21:30:44 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000017_18: Committed
21/03/23 21:30:44 INFO Executor: Finished task 23.0 in stage 1.0 (TID 24). 3592 bytes result sent to driver
21/03/23 21:30:44 INFO Executor: Finished task 17.0 in stage 1.0 (TID 18). 3592 bytes result sent to driver
21/03/23 21:30:44 INFO TaskSetManager: Starting task 39.0 in stage 1.0 (TID 40, localhost, executor driver, partition 39, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:44 INFO Executor: Running task 39.0 in stage 1.0 (TID 40)
21/03/23 21:30:44 INFO TaskSetManager: Starting task 40.0 in stage 1.0 (TID 41, localhost, executor driver, partition 40, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:44 INFO TaskSetManager: Finished task 23.0 in stage 1.0 (TID 24) in 8451 ms on localhost (executor driver) (24/81)
21/03/23 21:30:44 INFO TaskSetManager: Finished task 17.0 in stage 1.0 (TID 18) in 9527 ms on localhost (executor driver) (25/81)
21/03/23 21:30:44 INFO Executor: Running task 40.0 in stage 1.0 (TID 41)
21/03/23 21:30:44 INFO PythonUDFRunner: Times: total = 7264, boot = -589, init = 2170, finish = 5683
21/03/23 21:30:44 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000029_30' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000029
21/03/23 21:30:44 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000029_30: Committed
21/03/23 21:30:44 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 5234491392-5368709120, partition values: [empty row]
21/03/23 21:30:44 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 5368709120-5502926848, partition values: [empty row]
21/03/23 21:30:44 INFO Executor: Finished task 29.0 in stage 1.0 (TID 30). 3592 bytes result sent to driver
21/03/23 21:30:44 INFO TaskSetManager: Starting task 41.0 in stage 1.0 (TID 42, localhost, executor driver, partition 41, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:44 INFO TaskSetManager: Finished task 29.0 in stage 1.0 (TID 30) in 7629 ms on localhost (executor driver) (26/81)
21/03/23 21:30:44 INFO Executor: Running task 41.0 in stage 1.0 (TID 42)
21/03/23 21:30:44 INFO PythonUDFRunner: Times: total = 7447, boot = -761, init = 995, finish = 7213
21/03/23 21:30:44 INFO PythonUDFRunner: Times: total = 7317, boot = -914, init = 1449, finish = 6782
21/03/23 21:30:44 INFO PythonUDFRunner: Times: total = 8538, boot = -565, init = 718, finish = 8385
21/03/23 21:30:44 INFO PythonUDFRunner: Times: total = 8543, boot = -372, init = 954, finish = 7961
21/03/23 21:30:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:44 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:44 INFO PythonUDFRunner: Times: total = 7341, boot = -599, init = 2908, finish = 5032
21/03/23 21:30:44 INFO PythonUDFRunner: Times: total = 8632, boot = -493, init = 2379, finish = 6746
21/03/23 21:30:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:44 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:44 INFO PythonUDFRunner: Times: total = 7332, boot = -631, init = 3390, finish = 4573
21/03/23 21:30:44 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000031_32' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000031
21/03/23 21:30:44 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000031_32: Committed
21/03/23 21:30:44 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 5502926848-5637144576, partition values: [empty row]
21/03/23 21:30:44 INFO Executor: Finished task 31.0 in stage 1.0 (TID 32). 3592 bytes result sent to driver
21/03/23 21:30:44 INFO TaskSetManager: Starting task 42.0 in stage 1.0 (TID 43, localhost, executor driver, partition 42, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:44 INFO Executor: Running task 42.0 in stage 1.0 (TID 43)
21/03/23 21:30:44 INFO TaskSetManager: Finished task 31.0 in stage 1.0 (TID 32) in 7697 ms on localhost (executor driver) (27/81)
21/03/23 21:30:44 INFO PythonUDFRunner: Times: total = 8274, boot = -581, init = 2610, finish = 6245
21/03/23 21:30:44 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000021_22' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000021
21/03/23 21:30:44 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000021_22: Committed
21/03/23 21:30:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:44 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:44 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 5637144576-5771362304, partition values: [empty row]
21/03/23 21:30:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:44 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:45 INFO Executor: Finished task 21.0 in stage 1.0 (TID 22). 3592 bytes result sent to driver
21/03/23 21:30:45 INFO TaskSetManager: Starting task 43.0 in stage 1.0 (TID 44, localhost, executor driver, partition 43, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:45 INFO Executor: Running task 43.0 in stage 1.0 (TID 44)
21/03/23 21:30:45 INFO TaskSetManager: Finished task 21.0 in stage 1.0 (TID 22) in 9118 ms on localhost (executor driver) (28/81)
21/03/23 21:30:45 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 5771362304-5905580032, partition values: [empty row]
21/03/23 21:30:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:45 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:45 INFO PythonUDFRunner: Times: total = 8713, boot = -680, init = 784, finish = 8609
21/03/23 21:30:45 INFO PythonUDFRunner: Times: total = 8693, boot = -605, init = 1197, finish = 8101
21/03/23 21:30:45 INFO PythonUDFRunner: Times: total = 8403, boot = -758, init = 2363, finish = 6798
21/03/23 21:30:45 INFO PythonUDFRunner: Times: total = 8305, boot = -600, init = 2489, finish = 6416
21/03/23 21:30:45 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000026_27' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000026
21/03/23 21:30:45 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000026_27: Committed
21/03/23 21:30:45 INFO Executor: Finished task 26.0 in stage 1.0 (TID 27). 3592 bytes result sent to driver
21/03/23 21:30:45 INFO TaskSetManager: Starting task 44.0 in stage 1.0 (TID 45, localhost, executor driver, partition 44, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:45 INFO TaskSetManager: Finished task 26.0 in stage 1.0 (TID 27) in 9016 ms on localhost (executor driver) (29/81)
21/03/23 21:30:45 INFO Executor: Running task 44.0 in stage 1.0 (TID 45)
21/03/23 21:30:45 INFO PythonUDFRunner: Times: total = 8882, boot = -705, init = 984, finish = 8603
21/03/23 21:30:45 INFO PythonUDFRunner: Times: total = 8770, boot = -549, init = 1293, finish = 8026
21/03/23 21:30:45 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 5905580032-6039797760, partition values: [empty row]
21/03/23 21:30:45 INFO PythonUDFRunner: Times: total = 8703, boot = -629, init = 2331, finish = 7001
21/03/23 21:30:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:45 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:46 INFO PythonUDFRunner: Times: total = 8598, boot = -590, init = 2360, finish = 6828
21/03/23 21:30:46 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000028_29' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000028
21/03/23 21:30:46 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000028_29: Committed
21/03/23 21:30:46 INFO Executor: Finished task 28.0 in stage 1.0 (TID 29). 3592 bytes result sent to driver
21/03/23 21:30:46 INFO TaskSetManager: Starting task 45.0 in stage 1.0 (TID 46, localhost, executor driver, partition 45, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:46 INFO Executor: Running task 45.0 in stage 1.0 (TID 46)
21/03/23 21:30:46 INFO TaskSetManager: Finished task 28.0 in stage 1.0 (TID 29) in 9188 ms on localhost (executor driver) (30/81)
21/03/23 21:30:46 INFO PythonUDFRunner: Times: total = 9210, boot = -628, init = 871, finish = 8967
21/03/23 21:30:46 INFO PythonUDFRunner: Times: total = 9037, boot = -666, init = 1292, finish = 8411
21/03/23 21:30:46 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 6039797760-6174015488, partition values: [empty row]
21/03/23 21:30:46 INFO PythonUDFRunner: Times: total = 8909, boot = -659, init = 2408, finish = 7160
21/03/23 21:30:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:46 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:46 INFO PythonUDFRunner: Times: total = 8898, boot = -660, init = 2843, finish = 6715
21/03/23 21:30:46 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000030_31' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000030
21/03/23 21:30:46 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000030_31: Committed
21/03/23 21:30:46 INFO Executor: Finished task 30.0 in stage 1.0 (TID 31). 3592 bytes result sent to driver
21/03/23 21:30:46 INFO TaskSetManager: Starting task 46.0 in stage 1.0 (TID 47, localhost, executor driver, partition 46, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:46 INFO TaskSetManager: Finished task 30.0 in stage 1.0 (TID 31) in 9504 ms on localhost (executor driver) (31/81)
21/03/23 21:30:46 INFO Executor: Running task 46.0 in stage 1.0 (TID 47)
21/03/23 21:30:46 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 6174015488-6308233216, partition values: [empty row]
21/03/23 21:30:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:46 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:46 INFO PythonUDFRunner: Times: total = 9768, boot = -647, init = 908, finish = 9507
21/03/23 21:30:46 INFO PythonUDFRunner: Times: total = 9719, boot = -650, init = 1809, finish = 8560
21/03/23 21:30:46 INFO PythonUDFRunner: Times: total = 9717, boot = -433, init = 2741, finish = 7409
21/03/23 21:30:46 INFO PythonUDFRunner: Times: total = 9647, boot = -614, init = 3157, finish = 7104
21/03/23 21:30:46 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000027_28' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000027
21/03/23 21:30:46 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000027_28: Committed
21/03/23 21:30:46 INFO Executor: Finished task 27.0 in stage 1.0 (TID 28). 3592 bytes result sent to driver
21/03/23 21:30:46 INFO TaskSetManager: Starting task 47.0 in stage 1.0 (TID 48, localhost, executor driver, partition 47, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:46 INFO Executor: Running task 47.0 in stage 1.0 (TID 48)
21/03/23 21:30:46 INFO TaskSetManager: Finished task 27.0 in stage 1.0 (TID 28) in 10101 ms on localhost (executor driver) (32/81)
21/03/23 21:30:46 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 6308233216-6442450944, partition values: [empty row]
21/03/23 21:30:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:50 INFO PythonUDFRunner: Times: total = 7153, boot = -451, init = 585, finish = 7019
21/03/23 21:30:50 INFO PythonUDFRunner: Times: total = 7138, boot = -410, init = 980, finish = 6568
21/03/23 21:30:50 INFO PythonUDFRunner: Times: total = 7239, boot = -347, init = 1887, finish = 5699
21/03/23 21:30:50 INFO PythonUDFRunner: Times: total = 7196, boot = -330, init = 2058, finish = 5468
21/03/23 21:30:50 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000034_35' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000034
21/03/23 21:30:50 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000034_35: Committed
21/03/23 21:30:50 INFO Executor: Finished task 34.0 in stage 1.0 (TID 35). 3592 bytes result sent to driver
21/03/23 21:30:50 INFO TaskSetManager: Starting task 48.0 in stage 1.0 (TID 49, localhost, executor driver, partition 48, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:50 INFO TaskSetManager: Finished task 34.0 in stage 1.0 (TID 35) in 7522 ms on localhost (executor driver) (33/81)
21/03/23 21:30:50 INFO Executor: Running task 48.0 in stage 1.0 (TID 49)
21/03/23 21:30:50 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 6442450944-6576668672, partition values: [empty row]
21/03/23 21:30:50 INFO PythonUDFRunner: Times: total = 8174, boot = -481, init = 514, finish = 8141
21/03/23 21:30:50 INFO PythonUDFRunner: Times: total = 6912, boot = -461, init = 568, finish = 6805
21/03/23 21:30:50 INFO PythonUDFRunner: Times: total = 8236, boot = -410, init = 909, finish = 7737
21/03/23 21:30:50 INFO PythonUDFRunner: Times: total = 6873, boot = -341, init = 901, finish = 6313
21/03/23 21:30:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:51 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:51 INFO PythonUDFRunner: Times: total = 6946, boot = -418, init = 1823, finish = 5541
21/03/23 21:30:51 INFO PythonUDFRunner: Times: total = 8343, boot = -352, init = 2120, finish = 6575
21/03/23 21:30:51 INFO PythonUDFRunner: Times: total = 6935, boot = -299, init = 2096, finish = 5138
21/03/23 21:30:51 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000037_38' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000037
21/03/23 21:30:51 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000037_38: Committed
21/03/23 21:30:51 INFO PythonUDFRunner: Times: total = 8329, boot = -334, init = 2269, finish = 6394
21/03/23 21:30:51 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000032_33' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000032
21/03/23 21:30:51 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000032_33: Committed
21/03/23 21:30:51 INFO PythonUDFRunner: Times: total = 7149, boot = -511, init = 563, finish = 7097
21/03/23 21:30:51 INFO PythonUDFRunner: Times: total = 7138, boot = -445, init = 895, finish = 6688
21/03/23 21:30:51 INFO Executor: Finished task 37.0 in stage 1.0 (TID 38). 3592 bytes result sent to driver
21/03/23 21:30:51 INFO TaskSetManager: Starting task 49.0 in stage 1.0 (TID 50, localhost, executor driver, partition 49, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:51 INFO TaskSetManager: Finished task 37.0 in stage 1.0 (TID 38) in 7436 ms on localhost (executor driver) (34/81)
21/03/23 21:30:51 INFO Executor: Running task 49.0 in stage 1.0 (TID 50)
21/03/23 21:30:51 INFO Executor: Finished task 32.0 in stage 1.0 (TID 33). 3592 bytes result sent to driver
21/03/23 21:30:51 INFO TaskSetManager: Starting task 50.0 in stage 1.0 (TID 51, localhost, executor driver, partition 50, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:51 INFO TaskSetManager: Finished task 32.0 in stage 1.0 (TID 33) in 8605 ms on localhost (executor driver) (35/81)
21/03/23 21:30:51 INFO Executor: Running task 50.0 in stage 1.0 (TID 51)
21/03/23 21:30:51 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 6576668672-6710886400, partition values: [empty row]
21/03/23 21:30:51 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 6710886400-6845104128, partition values: [empty row]
21/03/23 21:30:51 INFO PythonUDFRunner: Times: total = 7231, boot = -352, init = 2382, finish = 5201
21/03/23 21:30:51 INFO PythonUDFRunner: Times: total = 7201, boot = -315, init = 2568, finish = 4948
21/03/23 21:30:51 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000038_39' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000038
21/03/23 21:30:51 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000038_39: Committed
21/03/23 21:30:51 INFO PythonUDFRunner: Times: total = 7061, boot = -328, init = 373, finish = 7016
21/03/23 21:30:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:51 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:51 INFO PythonUDFRunner: Times: total = 7029, boot = -424, init = 980, finish = 6473
21/03/23 21:30:51 INFO Executor: Finished task 38.0 in stage 1.0 (TID 39). 3592 bytes result sent to driver
21/03/23 21:30:51 INFO TaskSetManager: Starting task 51.0 in stage 1.0 (TID 52, localhost, executor driver, partition 51, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:51 INFO Executor: Running task 51.0 in stage 1.0 (TID 52)
21/03/23 21:30:51 INFO TaskSetManager: Finished task 38.0 in stage 1.0 (TID 39) in 7532 ms on localhost (executor driver) (36/81)
21/03/23 21:30:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:51 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:51 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 6845104128-6979321856, partition values: [empty row]
21/03/23 21:30:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:51 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:51 INFO PythonUDFRunner: Times: total = 7171, boot = -329, init = 1533, finish = 5967
21/03/23 21:30:51 INFO PythonUDFRunner: Times: total = 7145, boot = -234, init = 1569, finish = 5810
21/03/23 21:30:51 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000040_41' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000040
21/03/23 21:30:51 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000040_41: Committed
21/03/23 21:30:51 INFO Executor: Finished task 40.0 in stage 1.0 (TID 41). 3592 bytes result sent to driver
21/03/23 21:30:51 INFO TaskSetManager: Starting task 52.0 in stage 1.0 (TID 53, localhost, executor driver, partition 52, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:51 INFO TaskSetManager: Finished task 40.0 in stage 1.0 (TID 41) in 7353 ms on localhost (executor driver) (37/81)
21/03/23 21:30:51 INFO Executor: Running task 52.0 in stage 1.0 (TID 53)
21/03/23 21:30:51 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 6979321856-7113539584, partition values: [empty row]
21/03/23 21:30:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:51 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:51 INFO PythonUDFRunner: Times: total = 9128, boot = -334, init = 583, finish = 8879
21/03/23 21:30:51 INFO PythonUDFRunner: Times: total = 7239, boot = -597, init = 734, finish = 7102
21/03/23 21:30:51 INFO PythonUDFRunner: Times: total = 7119, boot = -284, init = 772, finish = 6631
21/03/23 21:30:52 INFO PythonUDFRunner: Times: total = 9102, boot = -430, init = 1129, finish = 8403
21/03/23 21:30:52 INFO PythonUDFRunner: Times: total = 7187, boot = -308, init = 1790, finish = 5705
21/03/23 21:30:52 INFO PythonUDFRunner: Times: total = 9183, boot = -336, init = 2749, finish = 6770
21/03/23 21:30:52 INFO PythonUDFRunner: Times: total = 8520, boot = -451, init = 486, finish = 8485
21/03/23 21:30:52 INFO PythonUDFRunner: Times: total = 8343, boot = -442, init = 464, finish = 8321
21/03/23 21:30:52 INFO PythonUDFRunner: Times: total = 8494, boot = -390, init = 912, finish = 7972
21/03/23 21:30:52 INFO PythonUDFRunner: Times: total = 8272, boot = -429, init = 948, finish = 7753
21/03/23 21:30:52 INFO PythonUDFRunner: Times: total = 9163, boot = -322, init = 2851, finish = 6634
21/03/23 21:30:52 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000033_34' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000033
21/03/23 21:30:52 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000033_34: Committed
21/03/23 21:30:52 INFO PythonUDFRunner: Times: total = 8337, boot = -469, init = 2191, finish = 6615
21/03/23 21:30:52 INFO PythonUDFRunner: Times: total = 8544, boot = -416, init = 2226, finish = 6734
21/03/23 21:30:52 INFO PythonUDFRunner: Times: total = 8326, boot = -430, init = 2361, finish = 6395
21/03/23 21:30:52 INFO PythonUDFRunner: Times: total = 7153, boot = -364, init = 2117, finish = 5400
21/03/23 21:30:52 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000042_43' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000042
21/03/23 21:30:52 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000042_43: Committed
21/03/23 21:30:52 INFO PythonUDFRunner: Times: total = 8450, boot = -453, init = 2395, finish = 6508
21/03/23 21:30:52 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000036_37' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000036
21/03/23 21:30:52 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000036_37: Committed
21/03/23 21:30:52 INFO Executor: Finished task 42.0 in stage 1.0 (TID 43). 3592 bytes result sent to driver
21/03/23 21:30:52 INFO PythonUDFRunner: Times: total = 5443, boot = -282, init = 319, finish = 5406
21/03/23 21:30:52 INFO TaskSetManager: Starting task 53.0 in stage 1.0 (TID 54, localhost, executor driver, partition 53, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:52 INFO Executor: Running task 53.0 in stage 1.0 (TID 54)
21/03/23 21:30:52 INFO Executor: Finished task 36.0 in stage 1.0 (TID 37). 3592 bytes result sent to driver
21/03/23 21:30:52 INFO Executor: Finished task 33.0 in stage 1.0 (TID 34). 3592 bytes result sent to driver
21/03/23 21:30:52 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000035_36' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000035
21/03/23 21:30:52 INFO TaskSetManager: Finished task 42.0 in stage 1.0 (TID 43) in 7780 ms on localhost (executor driver) (38/81)
21/03/23 21:30:52 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 7113539584-7247757312, partition values: [empty row]
21/03/23 21:30:52 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000035_36: Committed
21/03/23 21:30:52 INFO PythonUDFRunner: Times: total = 7468, boot = -350, init = 387, finish = 7431
21/03/23 21:30:52 INFO TaskSetManager: Starting task 54.0 in stage 1.0 (TID 55, localhost, executor driver, partition 54, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:52 INFO TaskSetManager: Starting task 55.0 in stage 1.0 (TID 56, localhost, executor driver, partition 55, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:52 INFO Executor: Finished task 35.0 in stage 1.0 (TID 36). 3592 bytes result sent to driver
21/03/23 21:30:52 INFO Executor: Running task 55.0 in stage 1.0 (TID 56)
21/03/23 21:30:52 INFO Executor: Running task 54.0 in stage 1.0 (TID 55)
21/03/23 21:30:52 INFO TaskSetManager: Starting task 56.0 in stage 1.0 (TID 57, localhost, executor driver, partition 56, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:52 INFO TaskSetManager: Finished task 35.0 in stage 1.0 (TID 36) in 9142 ms on localhost (executor driver) (39/81)
21/03/23 21:30:52 INFO TaskSetManager: Finished task 33.0 in stage 1.0 (TID 34) in 9707 ms on localhost (executor driver) (40/81)
21/03/23 21:30:52 INFO PythonUDFRunner: Times: total = 5410, boot = -323, init = 749, finish = 4984
21/03/23 21:30:52 INFO PythonUDFRunner: Times: total = 7956, boot = -331, init = 592, finish = 7695
21/03/23 21:30:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:52 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:52 INFO PythonUDFRunner: Times: total = 8103, boot = -416, init = 449, finish = 8070
21/03/23 21:30:52 INFO Executor: Running task 56.0 in stage 1.0 (TID 57)
21/03/23 21:30:52 INFO PythonUDFRunner: Times: total = 7832, boot = -326, init = 800, finish = 7358
21/03/23 21:30:52 INFO PythonUDFRunner: Times: total = 5581, boot = -192, init = 1575, finish = 4198
21/03/23 21:30:52 INFO PythonUDFRunner: Times: total = 7460, boot = -351, init = 917, finish = 6894
21/03/23 21:30:52 INFO PythonUDFRunner: Times: total = 8108, boot = -333, init = 902, finish = 7539
21/03/23 21:30:52 INFO TaskSetManager: Finished task 36.0 in stage 1.0 (TID 37) in 8937 ms on localhost (executor driver) (41/81)
21/03/23 21:30:52 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 7381975040-7516192768, partition values: [empty row]
21/03/23 21:30:52 INFO PythonUDFRunner: Times: total = 7458, boot = -565, init = 2205, finish = 5818
21/03/23 21:30:52 INFO PythonUDFRunner: Times: total = 5612, boot = -259, init = 1711, finish = 4160
21/03/23 21:30:52 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000047_48' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000047
21/03/23 21:30:52 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000047_48: Committed
21/03/23 21:30:52 INFO PythonUDFRunner: Times: total = 7866, boot = -349, init = 1939, finish = 6276
21/03/23 21:30:52 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 7247757312-7381975040, partition values: [empty row]
21/03/23 21:30:52 INFO PythonUDFRunner: Times: total = 8069, boot = -388, init = 1851, finish = 6606
21/03/23 21:30:52 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 7516192768-7650410496, partition values: [empty row]
21/03/23 21:30:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:52 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:52 INFO PythonUDFRunner: Times: total = 7941, boot = -134, init = 1976, finish = 6099
21/03/23 21:30:52 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000041_42' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000041
21/03/23 21:30:52 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000041_42: Committed
21/03/23 21:30:52 INFO Executor: Finished task 47.0 in stage 1.0 (TID 48). 3592 bytes result sent to driver
21/03/23 21:30:52 INFO TaskSetManager: Starting task 57.0 in stage 1.0 (TID 58, localhost, executor driver, partition 57, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:52 INFO Executor: Running task 57.0 in stage 1.0 (TID 58)
21/03/23 21:30:52 INFO TaskSetManager: Finished task 47.0 in stage 1.0 (TID 48) in 5901 ms on localhost (executor driver) (42/81)
21/03/23 21:30:52 INFO PythonUDFRunner: Times: total = 8087, boot = -327, init = 2034, finish = 6380
21/03/23 21:30:52 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000039_40' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000039
21/03/23 21:30:52 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000039_40: Committed
21/03/23 21:30:52 INFO PythonUDFRunner: Times: total = 7408, boot = -590, init = 2489, finish = 5509
21/03/23 21:30:52 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000043_44' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000043
21/03/23 21:30:52 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000043_44: Committed
21/03/23 21:30:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:52 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:52 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 7650410496-7784628224, partition values: [empty row]
21/03/23 21:30:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:52 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:52 INFO Executor: Finished task 39.0 in stage 1.0 (TID 40). 3592 bytes result sent to driver
21/03/23 21:30:52 INFO Executor: Finished task 41.0 in stage 1.0 (TID 42). 3592 bytes result sent to driver
21/03/23 21:30:52 INFO TaskSetManager: Starting task 58.0 in stage 1.0 (TID 59, localhost, executor driver, partition 58, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:52 INFO TaskSetManager: Starting task 59.0 in stage 1.0 (TID 60, localhost, executor driver, partition 59, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:52 INFO TaskSetManager: Finished task 41.0 in stage 1.0 (TID 42) in 8486 ms on localhost (executor driver) (43/81)
21/03/23 21:30:52 INFO Executor: Running task 58.0 in stage 1.0 (TID 59)
21/03/23 21:30:52 INFO Executor: Running task 59.0 in stage 1.0 (TID 60)
21/03/23 21:30:52 INFO TaskSetManager: Finished task 39.0 in stage 1.0 (TID 40) in 8533 ms on localhost (executor driver) (44/81)
21/03/23 21:30:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:53 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:53 INFO Executor: Finished task 43.0 in stage 1.0 (TID 44). 3592 bytes result sent to driver
21/03/23 21:30:53 INFO TaskSetManager: Starting task 60.0 in stage 1.0 (TID 61, localhost, executor driver, partition 60, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:53 INFO TaskSetManager: Finished task 43.0 in stage 1.0 (TID 44) in 7958 ms on localhost (executor driver) (45/81)
21/03/23 21:30:53 INFO Executor: Running task 60.0 in stage 1.0 (TID 61)
21/03/23 21:30:53 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 7918845952-8053063680, partition values: [empty row]
21/03/23 21:30:53 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 7784628224-7918845952, partition values: [empty row]
21/03/23 21:30:53 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 8053063680-8187281408, partition values: [empty row]
21/03/23 21:30:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:53 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:53 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:53 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:54 INFO PythonUDFRunner: Times: total = 7551, boot = -252, init = 276, finish = 7527
21/03/23 21:30:54 INFO PythonUDFRunner: Times: total = 7598, boot = -291, init = 888, finish = 7001
21/03/23 21:30:54 INFO PythonUDFRunner: Times: total = 7665, boot = -173, init = 1975, finish = 5863
21/03/23 21:30:54 INFO PythonUDFRunner: Times: total = 7657, boot = -263, init = 2249, finish = 5671
21/03/23 21:30:54 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000046_47' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000046
21/03/23 21:30:54 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000046_47: Committed
21/03/23 21:30:54 INFO Executor: Finished task 46.0 in stage 1.0 (TID 47). 3592 bytes result sent to driver
21/03/23 21:30:54 INFO TaskSetManager: Starting task 61.0 in stage 1.0 (TID 62, localhost, executor driver, partition 61, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:54 INFO TaskSetManager: Finished task 46.0 in stage 1.0 (TID 47) in 7843 ms on localhost (executor driver) (46/81)
21/03/23 21:30:54 INFO Executor: Running task 61.0 in stage 1.0 (TID 62)
21/03/23 21:30:54 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 8187281408-8321499136, partition values: [empty row]
21/03/23 21:30:54 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:54 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:54 INFO PythonUDFRunner: Times: total = 8537, boot = -241, init = 270, finish = 8508
21/03/23 21:30:54 INFO PythonUDFRunner: Times: total = 8546, boot = -261, init = 830, finish = 7977
21/03/23 21:30:54 INFO PythonUDFRunner: Times: total = 8614, boot = -179, init = 1784, finish = 7009
21/03/23 21:30:54 INFO PythonUDFRunner: Times: total = 8582, boot = -228, init = 2008, finish = 6802
21/03/23 21:30:54 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000044_45' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000044
21/03/23 21:30:54 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000044_45: Committed
21/03/23 21:30:54 INFO Executor: Finished task 44.0 in stage 1.0 (TID 45). 3592 bytes result sent to driver
21/03/23 21:30:54 INFO TaskSetManager: Starting task 62.0 in stage 1.0 (TID 63, localhost, executor driver, partition 62, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:54 INFO Executor: Running task 62.0 in stage 1.0 (TID 63)
21/03/23 21:30:54 INFO TaskSetManager: Finished task 44.0 in stage 1.0 (TID 45) in 8827 ms on localhost (executor driver) (47/81)
21/03/23 21:30:54 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 8321499136-8455716864, partition values: [empty row]
21/03/23 21:30:54 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:54 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:54 INFO PythonUDFRunner: Times: total = 8802, boot = -357, init = 386, finish = 8773
21/03/23 21:30:54 INFO PythonUDFRunner: Times: total = 8746, boot = -326, init = 906, finish = 8166
21/03/23 21:30:55 INFO PythonUDFRunner: Times: total = 8776, boot = -247, init = 2165, finish = 6858
21/03/23 21:30:55 INFO PythonUDFRunner: Times: total = 8764, boot = -343, init = 2387, finish = 6720
21/03/23 21:30:55 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000045_46' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000045
21/03/23 21:30:55 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000045_46: Committed
21/03/23 21:30:55 INFO Executor: Finished task 45.0 in stage 1.0 (TID 46). 3635 bytes result sent to driver
21/03/23 21:30:55 INFO TaskSetManager: Starting task 63.0 in stage 1.0 (TID 64, localhost, executor driver, partition 63, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:55 INFO TaskSetManager: Finished task 45.0 in stage 1.0 (TID 46) in 9137 ms on localhost (executor driver) (48/81)
21/03/23 21:30:55 INFO Executor: Running task 63.0 in stage 1.0 (TID 64)
21/03/23 21:30:55 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 8455716864-8589934592, partition values: [empty row]
21/03/23 21:30:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:55 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:58 INFO PythonUDFRunner: Times: total = 6322, boot = -236, init = 272, finish = 6286
21/03/23 21:30:58 INFO PythonUDFRunner: Times: total = 6333, boot = -274, init = 834, finish = 5773
21/03/23 21:30:58 INFO PythonUDFRunner: Times: total = 6425, boot = -104, init = 1226, finish = 5303
21/03/23 21:30:58 INFO PythonUDFRunner: Times: total = 6388, boot = -145, init = 1428, finish = 5105
21/03/23 21:30:58 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000052_53' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000052
21/03/23 21:30:58 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000052_53: Committed
21/03/23 21:30:58 INFO Executor: Finished task 52.0 in stage 1.0 (TID 53). 3592 bytes result sent to driver
21/03/23 21:30:58 INFO TaskSetManager: Starting task 64.0 in stage 1.0 (TID 65, localhost, executor driver, partition 64, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:58 INFO Executor: Running task 64.0 in stage 1.0 (TID 65)
21/03/23 21:30:58 INFO TaskSetManager: Finished task 52.0 in stage 1.0 (TID 53) in 6546 ms on localhost (executor driver) (49/81)
21/03/23 21:30:58 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 8589934592-8724152320, partition values: [empty row]
21/03/23 21:30:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:58 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:58 INFO PythonUDFRunner: Times: total = 7660, boot = -228, init = 262, finish = 7626
21/03/23 21:30:58 INFO PythonUDFRunner: Times: total = 7623, boot = -282, init = 971, finish = 6934
21/03/23 21:30:58 INFO PythonUDFRunner: Times: total = 7349, boot = -340, init = 373, finish = 7316
21/03/23 21:30:58 INFO PythonUDFRunner: Times: total = 7344, boot = -308, init = 853, finish = 6799
21/03/23 21:30:58 INFO PythonUDFRunner: Times: total = 7711, boot = -157, init = 1525, finish = 6343
21/03/23 21:30:58 INFO PythonUDFRunner: Times: total = 7699, boot = -185, init = 1709, finish = 6175
21/03/23 21:30:58 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000048_49' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000048
21/03/23 21:30:58 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000048_49: Committed
21/03/23 21:30:58 INFO Executor: Finished task 48.0 in stage 1.0 (TID 49). 3592 bytes result sent to driver
21/03/23 21:30:58 INFO TaskSetManager: Starting task 65.0 in stage 1.0 (TID 66, localhost, executor driver, partition 65, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:58 INFO TaskSetManager: Finished task 48.0 in stage 1.0 (TID 49) in 7853 ms on localhost (executor driver) (50/81)
21/03/23 21:30:58 INFO Executor: Running task 65.0 in stage 1.0 (TID 66)
21/03/23 21:30:58 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 8724152320-8858370048, partition values: [empty row]
21/03/23 21:30:58 INFO PythonUDFRunner: Times: total = 7479, boot = -210, init = 2055, finish = 5634
21/03/23 21:30:58 INFO PythonUDFRunner: Times: total = 7309, boot = -342, init = 375, finish = 7276
21/03/23 21:30:58 INFO PythonUDFRunner: Times: total = 7296, boot = -343, init = 832, finish = 6807
21/03/23 21:30:58 INFO PythonUDFRunner: Times: total = 7419, boot = -319, init = 2270, finish = 5468
21/03/23 21:30:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:58 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:58 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000049_50' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000049
21/03/23 21:30:58 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000049_50: Committed
21/03/23 21:30:58 INFO Executor: Finished task 49.0 in stage 1.0 (TID 50). 3592 bytes result sent to driver
21/03/23 21:30:58 INFO TaskSetManager: Starting task 66.0 in stage 1.0 (TID 67, localhost, executor driver, partition 66, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:58 INFO Executor: Running task 66.0 in stage 1.0 (TID 67)
21/03/23 21:30:58 INFO TaskSetManager: Finished task 49.0 in stage 1.0 (TID 50) in 7708 ms on localhost (executor driver) (51/81)
21/03/23 21:30:58 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 8858370048-8992587776, partition values: [empty row]
21/03/23 21:30:58 INFO PythonUDFRunner: Times: total = 7384, boot = -207, init = 1899, finish = 5692
21/03/23 21:30:59 INFO PythonUDFRunner: Times: total = 7366, boot = -272, init = 2241, finish = 5397
21/03/23 21:30:59 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000051_52' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000051
21/03/23 21:30:59 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000051_52: Committed
21/03/23 21:30:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:59 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:59 INFO Executor: Finished task 51.0 in stage 1.0 (TID 52). 3635 bytes result sent to driver
21/03/23 21:30:59 INFO TaskSetManager: Starting task 67.0 in stage 1.0 (TID 68, localhost, executor driver, partition 67, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:59 INFO TaskSetManager: Finished task 51.0 in stage 1.0 (TID 52) in 7627 ms on localhost (executor driver) (52/81)
21/03/23 21:30:59 INFO Executor: Running task 67.0 in stage 1.0 (TID 68)
21/03/23 21:30:59 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 8992587776-9126805504, partition values: [empty row]
21/03/23 21:30:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:30:59 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:30:59 INFO PythonUDFRunner: Times: total = 8260, boot = -253, init = 301, finish = 8212
21/03/23 21:30:59 INFO PythonUDFRunner: Times: total = 8199, boot = -330, init = 896, finish = 7633
21/03/23 21:30:59 INFO PythonUDFRunner: Times: total = 8187, boot = -261, init = 1494, finish = 6954
21/03/23 21:30:59 INFO PythonUDFRunner: Times: total = 8235, boot = -325, init = 1612, finish = 6948
21/03/23 21:30:59 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000050_51' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000050
21/03/23 21:30:59 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000050_51: Committed
21/03/23 21:30:59 INFO Executor: Finished task 50.0 in stage 1.0 (TID 51). 3592 bytes result sent to driver
21/03/23 21:30:59 INFO TaskSetManager: Starting task 68.0 in stage 1.0 (TID 69, localhost, executor driver, partition 68, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:30:59 INFO Executor: Running task 68.0 in stage 1.0 (TID 69)
21/03/23 21:30:59 INFO TaskSetManager: Finished task 50.0 in stage 1.0 (TID 51) in 8495 ms on localhost (executor driver) (53/81)
21/03/23 21:30:59 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 9126805504-9261023232, partition values: [empty row]
21/03/23 21:31:00 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:31:00 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:31:00 INFO PythonUDFRunner: Times: total = 7472, boot = -401, init = 493, finish = 7380
21/03/23 21:31:00 INFO PythonUDFRunner: Times: total = 7267, boot = -450, init = 1185, finish = 6532
21/03/23 21:31:00 INFO PythonUDFRunner: Times: total = 7844, boot = -474, init = 600, finish = 7718
21/03/23 21:31:00 INFO PythonUDFRunner: Times: total = 7215, boot = -531, init = 2154, finish = 5592
21/03/23 21:31:00 INFO PythonUDFRunner: Times: total = 7816, boot = -505, init = 1230, finish = 7091
21/03/23 21:31:00 INFO PythonUDFRunner: Times: total = 6378, boot = -240, init = 276, finish = 6342
21/03/23 21:31:00 INFO PythonUDFRunner: Times: total = 6360, boot = -188, init = 1007, finish = 5541
21/03/23 21:31:00 INFO PythonUDFRunner: Times: total = 7210, boot = -603, init = 2602, finish = 5211
21/03/23 21:31:00 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000059_60' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000059
21/03/23 21:31:00 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000059_60: Committed
21/03/23 21:31:00 INFO Executor: Finished task 59.0 in stage 1.0 (TID 60). 3635 bytes result sent to driver
21/03/23 21:31:00 INFO TaskSetManager: Starting task 69.0 in stage 1.0 (TID 70, localhost, executor driver, partition 69, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:31:00 INFO TaskSetManager: Finished task 59.0 in stage 1.0 (TID 60) in 7662 ms on localhost (executor driver) (54/81)
21/03/23 21:31:00 INFO Executor: Running task 69.0 in stage 1.0 (TID 70)
21/03/23 21:31:00 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 9261023232-9395240960, partition values: [empty row]
21/03/23 21:31:00 INFO PythonUDFRunner: Times: total = 7936, boot = -530, init = 2255, finish = 6211
21/03/23 21:31:00 INFO PythonUDFRunner: Times: total = 6407, boot = -66, init = 1700, finish = 4773
21/03/23 21:31:00 INFO PythonUDFRunner: Times: total = 6396, boot = -109, init = 1872, finish = 4633
21/03/23 21:31:00 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000061_62' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000061
21/03/23 21:31:00 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000061_62: Committed
21/03/23 21:31:00 INFO PythonUDFRunner: Times: total = 7939, boot = -582, init = 2674, finish = 5847
21/03/23 21:31:00 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:31:00 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:31:00 INFO Executor: Finished task 61.0 in stage 1.0 (TID 62). 3592 bytes result sent to driver
21/03/23 21:31:00 INFO TaskSetManager: Starting task 70.0 in stage 1.0 (TID 71, localhost, executor driver, partition 70, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:31:00 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000054_55' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000054
21/03/23 21:31:00 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000054_55: Committed
21/03/23 21:31:00 INFO Executor: Finished task 54.0 in stage 1.0 (TID 55). 3592 bytes result sent to driver
21/03/23 21:31:00 INFO Executor: Running task 70.0 in stage 1.0 (TID 71)
21/03/23 21:31:00 INFO TaskSetManager: Finished task 61.0 in stage 1.0 (TID 62) in 6577 ms on localhost (executor driver) (55/81)
21/03/23 21:31:00 INFO TaskSetManager: Starting task 71.0 in stage 1.0 (TID 72, localhost, executor driver, partition 71, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:31:00 INFO Executor: Running task 71.0 in stage 1.0 (TID 72)
21/03/23 21:31:00 INFO TaskSetManager: Finished task 54.0 in stage 1.0 (TID 55) in 8247 ms on localhost (executor driver) (56/81)
21/03/23 21:31:00 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 9395240960-9529458688, partition values: [empty row]
21/03/23 21:31:00 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 9529458688-9663676416, partition values: [empty row]
21/03/23 21:31:00 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:31:00 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:31:01 INFO PythonUDFRunner: Times: total = 8032, boot = -493, init = 585, finish = 7940
21/03/23 21:31:01 INFO PythonUDFRunner: Times: total = 7816, boot = -531, init = 1205, finish = 7142
21/03/23 21:31:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:31:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:31:01 INFO PythonUDFRunner: Times: total = 8402, boot = -539, init = 620, finish = 8321
21/03/23 21:31:01 INFO PythonUDFRunner: Times: total = 7900, boot = -490, init = 2338, finish = 6052
21/03/23 21:31:01 INFO PythonUDFRunner: Times: total = 8374, boot = -465, init = 1290, finish = 7549
21/03/23 21:31:01 INFO PythonUDFRunner: Times: total = 7873, boot = -490, init = 2620, finish = 5743
21/03/23 21:31:01 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000058_59' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000058
21/03/23 21:31:01 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000058_59: Committed
21/03/23 21:31:01 INFO Executor: Finished task 58.0 in stage 1.0 (TID 59). 3592 bytes result sent to driver
21/03/23 21:31:01 INFO TaskSetManager: Starting task 72.0 in stage 1.0 (TID 73, localhost, executor driver, partition 72, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:31:01 INFO TaskSetManager: Finished task 58.0 in stage 1.0 (TID 59) in 8211 ms on localhost (executor driver) (57/81)
21/03/23 21:31:01 INFO Executor: Running task 72.0 in stage 1.0 (TID 73)
21/03/23 21:31:01 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 9663676416-9797894144, partition values: [empty row]
21/03/23 21:31:01 INFO PythonUDFRunner: Times: total = 8444, boot = -528, init = 2968, finish = 6004
21/03/23 21:31:01 INFO PythonUDFRunner: Times: total = 8381, boot = -570, init = 634, finish = 8317
21/03/23 21:31:01 INFO PythonUDFRunner: Times: total = 8318, boot = -350, init = 1082, finish = 7586
21/03/23 21:31:01 INFO PythonUDFRunner: Times: total = 8818, boot = -338, init = 557, finish = 8599
21/03/23 21:31:01 INFO PythonUDFRunner: Times: total = 8812, boot = -328, init = 1120, finish = 8020
21/03/23 21:31:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:31:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:31:01 INFO PythonUDFRunner: Times: total = 8412, boot = -673, init = 3481, finish = 5604
21/03/23 21:31:01 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000056_57' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000056
21/03/23 21:31:01 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000056_57: Committed
21/03/23 21:31:01 INFO Executor: Finished task 56.0 in stage 1.0 (TID 57). 3592 bytes result sent to driver
21/03/23 21:31:01 INFO PythonUDFRunner: Times: total = 8364, boot = -537, init = 2097, finish = 6804
21/03/23 21:31:01 INFO TaskSetManager: Starting task 73.0 in stage 1.0 (TID 74, localhost, executor driver, partition 73, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:31:01 INFO Executor: Running task 73.0 in stage 1.0 (TID 74)
21/03/23 21:31:01 INFO TaskSetManager: Finished task 56.0 in stage 1.0 (TID 57) in 8776 ms on localhost (executor driver) (58/81)
21/03/23 21:31:01 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 9797894144-9932111872, partition values: [empty row]
21/03/23 21:31:01 INFO PythonUDFRunner: Times: total = 8341, boot = -394, init = 2202, finish = 6533
21/03/23 21:31:01 INFO PythonUDFRunner: Times: total = 8928, boot = -430, init = 2115, finish = 7243
21/03/23 21:31:01 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000057_58' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000057
21/03/23 21:31:01 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000057_58: Committed
21/03/23 21:31:01 INFO PythonUDFRunner: Times: total = 8894, boot = -479, init = 2568, finish = 6805
21/03/23 21:31:01 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000053_54' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000053
21/03/23 21:31:01 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000053_54: Committed
21/03/23 21:31:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:31:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:31:01 INFO Executor: Finished task 53.0 in stage 1.0 (TID 54). 3592 bytes result sent to driver
21/03/23 21:31:01 INFO Executor: Finished task 57.0 in stage 1.0 (TID 58). 3592 bytes result sent to driver
21/03/23 21:31:01 INFO TaskSetManager: Starting task 74.0 in stage 1.0 (TID 75, localhost, executor driver, partition 74, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:31:01 INFO Executor: Running task 74.0 in stage 1.0 (TID 75)
21/03/23 21:31:01 INFO TaskSetManager: Starting task 75.0 in stage 1.0 (TID 76, localhost, executor driver, partition 75, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:31:01 INFO TaskSetManager: Finished task 53.0 in stage 1.0 (TID 54) in 9075 ms on localhost (executor driver) (59/81)
21/03/23 21:31:01 INFO Executor: Running task 75.0 in stage 1.0 (TID 76)
21/03/23 21:31:01 INFO TaskSetManager: Finished task 57.0 in stage 1.0 (TID 58) in 8635 ms on localhost (executor driver) (60/81)
21/03/23 21:31:01 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 10066329600-10200547328, partition values: [empty row]
21/03/23 21:31:01 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 9932111872-10066329600, partition values: [empty row]
21/03/23 21:31:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:31:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:31:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:31:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:31:01 INFO PythonUDFRunner: Times: total = 6624, boot = -216, init = 264, finish = 6576
21/03/23 21:31:01 INFO PythonUDFRunner: Times: total = 6601, boot = -255, init = 1186, finish = 5670
21/03/23 21:31:01 INFO PythonUDFRunner: Times: total = 6676, boot = -201, init = 2071, finish = 4806
21/03/23 21:31:01 INFO PythonUDFRunner: Times: total = 6661, boot = -132, init = 2221, finish = 4572
21/03/23 21:31:01 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000063_64' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000063
21/03/23 21:31:01 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000063_64: Committed
21/03/23 21:31:01 INFO Executor: Finished task 63.0 in stage 1.0 (TID 64). 3592 bytes result sent to driver
21/03/23 21:31:01 INFO TaskSetManager: Starting task 76.0 in stage 1.0 (TID 77, localhost, executor driver, partition 76, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:31:01 INFO Executor: Running task 76.0 in stage 1.0 (TID 77)
21/03/23 21:31:01 INFO TaskSetManager: Finished task 63.0 in stage 1.0 (TID 64) in 6824 ms on localhost (executor driver) (61/81)
21/03/23 21:31:02 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 10200547328-10334765056, partition values: [empty row]
21/03/23 21:31:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:31:02 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:31:02 INFO PythonUDFRunner: Times: total = 9598, boot = -488, init = 582, finish = 9504
21/03/23 21:31:02 INFO PythonUDFRunner: Times: total = 9544, boot = -538, init = 1016, finish = 9066
21/03/23 21:31:02 INFO PythonUDFRunner: Times: total = 9620, boot = -522, init = 2839, finish = 7303
21/03/23 21:31:02 INFO PythonUDFRunner: Times: total = 9563, boot = -439, init = 2999, finish = 7003
21/03/23 21:31:02 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000055_56' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000055
21/03/23 21:31:02 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000055_56: Committed
21/03/23 21:31:02 INFO Executor: Finished task 55.0 in stage 1.0 (TID 56). 3592 bytes result sent to driver
21/03/23 21:31:02 INFO TaskSetManager: Starting task 77.0 in stage 1.0 (TID 78, localhost, executor driver, partition 77, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:31:02 INFO TaskSetManager: Finished task 55.0 in stage 1.0 (TID 56) in 9974 ms on localhost (executor driver) (62/81)
21/03/23 21:31:02 INFO Executor: Running task 77.0 in stage 1.0 (TID 78)
21/03/23 21:31:02 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 10334765056-10468982784, partition values: [empty row]
21/03/23 21:31:02 INFO PythonUDFRunner: Times: total = 9561, boot = -399, init = 454, finish = 9506
21/03/23 21:31:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:31:02 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:31:02 INFO PythonUDFRunner: Times: total = 9549, boot = -497, init = 1351, finish = 8695
21/03/23 21:31:02 INFO PythonUDFRunner: Times: total = 9607, boot = -496, init = 2837, finish = 7266
21/03/23 21:31:02 INFO PythonUDFRunner: Times: total = 9599, boot = -408, init = 3321, finish = 6686
21/03/23 21:31:02 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000060_61' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000060
21/03/23 21:31:02 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000060_61: Committed
21/03/23 21:31:02 INFO Executor: Finished task 60.0 in stage 1.0 (TID 61). 3592 bytes result sent to driver
21/03/23 21:31:02 INFO TaskSetManager: Starting task 78.0 in stage 1.0 (TID 79, localhost, executor driver, partition 78, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:31:02 INFO TaskSetManager: Finished task 60.0 in stage 1.0 (TID 61) in 9855 ms on localhost (executor driver) (63/81)
21/03/23 21:31:02 INFO Executor: Running task 78.0 in stage 1.0 (TID 79)
21/03/23 21:31:02 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 10468982784-10603200512, partition values: [empty row]
21/03/23 21:31:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:31:02 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:31:04 INFO PythonUDFRunner: Times: total = 10086, boot = -221, init = 253, finish = 10054
21/03/23 21:31:04 INFO PythonUDFRunner: Times: total = 10068, boot = -216, init = 802, finish = 9482
21/03/23 21:31:04 INFO PythonUDFRunner: Times: total = 10176, boot = -137, init = 1989, finish = 8324
21/03/23 21:31:05 INFO PythonUDFRunner: Times: total = 10140, boot = -188, init = 2249, finish = 8079
21/03/23 21:31:05 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000062_63' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000062
21/03/23 21:31:05 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000062_63: Committed
21/03/23 21:31:05 INFO Executor: Finished task 62.0 in stage 1.0 (TID 63). 3592 bytes result sent to driver
21/03/23 21:31:05 INFO TaskSetManager: Starting task 79.0 in stage 1.0 (TID 80, localhost, executor driver, partition 79, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:31:05 INFO TaskSetManager: Finished task 62.0 in stage 1.0 (TID 63) in 10372 ms on localhost (executor driver) (64/81)
21/03/23 21:31:05 INFO Executor: Running task 79.0 in stage 1.0 (TID 80)
21/03/23 21:31:05 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 10603200512-10737418240, partition values: [empty row]
21/03/23 21:31:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:31:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:31:06 INFO PythonUDFRunner: Times: total = 7996, boot = -120, init = 148, finish = 7968
21/03/23 21:31:06 INFO PythonUDFRunner: Times: total = 7979, boot = -163, init = 1027, finish = 7115
21/03/23 21:31:06 INFO PythonUDFRunner: Times: total = 7793, boot = -170, init = 217, finish = 7746
21/03/23 21:31:06 INFO PythonUDFRunner: Times: total = 7763, boot = -183, init = 716, finish = 7230
21/03/23 21:31:06 INFO PythonUDFRunner: Times: total = 6883, boot = -170, init = 206, finish = 6847
21/03/23 21:31:06 INFO PythonUDFRunner: Times: total = 6866, boot = -211, init = 1061, finish = 6016
21/03/23 21:31:06 INFO PythonUDFRunner: Times: total = 7806, boot = -139, init = 1964, finish = 5981
21/03/23 21:31:06 INFO PythonUDFRunner: Times: total = 8288, boot = -93, init = 2023, finish = 6358
21/03/23 21:31:06 INFO PythonUDFRunner: Times: total = 7798, boot = -210, init = 2282, finish = 5726
21/03/23 21:31:06 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000065_66' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000065
21/03/23 21:31:06 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000065_66: Committed
21/03/23 21:31:06 INFO Executor: Finished task 65.0 in stage 1.0 (TID 66). 3592 bytes result sent to driver
21/03/23 21:31:06 INFO TaskSetManager: Starting task 80.0 in stage 1.0 (TID 81, localhost, executor driver, partition 80, PROCESS_LOCAL, 8269 bytes)
21/03/23 21:31:06 INFO TaskSetManager: Finished task 65.0 in stage 1.0 (TID 66) in 7950 ms on localhost (executor driver) (65/81)
21/03/23 21:31:06 INFO Executor: Running task 80.0 in stage 1.0 (TID 81)
21/03/23 21:31:06 INFO FileScanRDD: Reading File path: file:///data/zillow/Z2_preprocessed/zillow_Z2_10G.csv, range: 10737418240-10748681558, partition values: [empty row]
21/03/23 21:31:06 INFO PythonUDFRunner: Times: total = 8272, boot = -99, init = 2213, finish = 6158
21/03/23 21:31:06 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000064_65' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000064
21/03/23 21:31:06 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000064_65: Committed
21/03/23 21:31:06 INFO Executor: Finished task 64.0 in stage 1.0 (TID 65). 3592 bytes result sent to driver
21/03/23 21:31:06 INFO TaskSetManager: Finished task 64.0 in stage 1.0 (TID 65) in 8475 ms on localhost (executor driver) (66/81)
21/03/23 21:31:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/03/23 21:31:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/23 21:31:06 INFO PythonUDFRunner: Times: total = 6847, boot = -457, init = 1786, finish = 5518
21/03/23 21:31:06 INFO PythonUDFRunner: Times: total = 6832, boot = -326, init = 1879, finish = 5279
21/03/23 21:31:06 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000068_69' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000068
21/03/23 21:31:06 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000068_69: Committed
21/03/23 21:31:06 INFO Executor: Finished task 68.0 in stage 1.0 (TID 69). 3592 bytes result sent to driver
21/03/23 21:31:06 INFO TaskSetManager: Finished task 68.0 in stage 1.0 (TID 69) in 7183 ms on localhost (executor driver) (67/81)
21/03/23 21:31:07 INFO PythonUDFRunner: Times: total = 786, boot = -343, init = 367, finish = 762
21/03/23 21:31:07 INFO PythonUDFRunner: Times: total = 757, boot = -396, init = 853, finish = 300
21/03/23 21:31:07 INFO PythonUDFRunner: Times: total = 8619, boot = -217, init = 261, finish = 8575
21/03/23 21:31:07 INFO PythonUDFRunner: Times: total = 8592, boot = -232, init = 1240, finish = 7584
21/03/23 21:31:07 INFO PythonUDFRunner: Times: total = 8673, boot = -78, init = 2576, finish = 6175
21/03/23 21:31:07 INFO PythonUDFRunner: Times: total = 8631, boot = -126, init = 2759, finish = 5998
21/03/23 21:31:07 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000066_67' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000066
21/03/23 21:31:07 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000066_67: Committed
21/03/23 21:31:07 INFO Executor: Finished task 66.0 in stage 1.0 (TID 67). 3592 bytes result sent to driver
21/03/23 21:31:07 INFO TaskSetManager: Finished task 66.0 in stage 1.0 (TID 67) in 8769 ms on localhost (executor driver) (68/81)
21/03/23 21:31:07 INFO PythonUDFRunner: Times: total = 7106, boot = -91, init = 120, finish = 7077
21/03/23 21:31:07 INFO PythonUDFRunner: Times: total = 7077, boot = -158, init = 809, finish = 6426
21/03/23 21:31:07 INFO PythonUDFRunner: Times: total = 7158, boot = -116, init = 1589, finish = 5685
21/03/23 21:31:07 INFO PythonUDFRunner: Times: total = 7153, boot = -121, init = 1854, finish = 5420
21/03/23 21:31:07 INFO PythonUDFRunner: Times: total = 8750, boot = -266, init = 295, finish = 8721
21/03/23 21:31:07 INFO PythonUDFRunner: Times: total = 1114, boot = -179, init = 908, finish = 385
21/03/23 21:31:07 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000069_70' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000069
21/03/23 21:31:07 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000069_70: Committed
21/03/23 21:31:07 INFO Executor: Finished task 69.0 in stage 1.0 (TID 70). 3592 bytes result sent to driver
21/03/23 21:31:07 INFO TaskSetManager: Finished task 69.0 in stage 1.0 (TID 70) in 7301 ms on localhost (executor driver) (69/81)
21/03/23 21:31:07 INFO PythonUDFRunner: Times: total = 8721, boot = -283, init = 1086, finish = 7918
21/03/23 21:31:07 INFO PythonUDFRunner: Times: total = 7209, boot = -232, init = 248, finish = 7193
21/03/23 21:31:08 INFO PythonUDFRunner: Times: total = 7191, boot = -141, init = 559, finish = 6773
21/03/23 21:31:08 INFO PythonUDFRunner: Times: total = 1089, boot = -235, init = 1311, finish = 13
21/03/23 21:31:08 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000080_81' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000080
21/03/23 21:31:08 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000080_81: Committed
21/03/23 21:31:08 INFO Executor: Finished task 80.0 in stage 1.0 (TID 81). 3549 bytes result sent to driver
21/03/23 21:31:08 INFO TaskSetManager: Finished task 80.0 in stage 1.0 (TID 81) in 1316 ms on localhost (executor driver) (70/81)
21/03/23 21:31:08 INFO PythonUDFRunner: Times: total = 8768, boot = -187, init = 2521, finish = 6434
21/03/23 21:31:08 INFO PythonUDFRunner: Times: total = 7197, boot = -104, init = 1454, finish = 5847
21/03/23 21:31:08 INFO PythonUDFRunner: Times: total = 8760, boot = -255, init = 2849, finish = 6166
21/03/23 21:31:08 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000067_68' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000067
21/03/23 21:31:08 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000067_68: Committed
21/03/23 21:31:08 INFO Executor: Finished task 67.0 in stage 1.0 (TID 68). 3592 bytes result sent to driver
21/03/23 21:31:08 INFO TaskSetManager: Finished task 67.0 in stage 1.0 (TID 68) in 8975 ms on localhost (executor driver) (71/81)
21/03/23 21:31:08 INFO PythonUDFRunner: Times: total = 7166, boot = -206, init = 1846, finish = 5526
21/03/23 21:31:08 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000070_71' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000070
21/03/23 21:31:08 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000070_71: Committed
21/03/23 21:31:08 INFO Executor: Finished task 70.0 in stage 1.0 (TID 71). 3592 bytes result sent to driver
21/03/23 21:31:08 INFO TaskSetManager: Finished task 70.0 in stage 1.0 (TID 71) in 7396 ms on localhost (executor driver) (72/81)
21/03/23 21:31:08 INFO PythonUDFRunner: Times: total = 7830, boot = -121, init = 178, finish = 7773
21/03/23 21:31:08 INFO PythonUDFRunner: Times: total = 7772, boot = -252, init = 1236, finish = 6788
21/03/23 21:31:08 INFO PythonUDFRunner: Times: total = 7779, boot = -203, init = 2238, finish = 5744
21/03/23 21:31:08 INFO PythonUDFRunner: Times: total = 7674, boot = -286, init = 2724, finish = 5236
21/03/23 21:31:08 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000071_72' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000071
21/03/23 21:31:08 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000071_72: Committed
21/03/23 21:31:08 INFO Executor: Finished task 71.0 in stage 1.0 (TID 72). 3592 bytes result sent to driver
21/03/23 21:31:08 INFO TaskSetManager: Finished task 71.0 in stage 1.0 (TID 72) in 7949 ms on localhost (executor driver) (73/81)
21/03/23 21:31:08 INFO PythonUDFRunner: Times: total = 6861, boot = -124, init = 171, finish = 6814
21/03/23 21:31:08 INFO PythonUDFRunner: Times: total = 6824, boot = -193, init = 1019, finish = 5998
21/03/23 21:31:08 INFO PythonUDFRunner: Times: total = 6828, boot = -134, init = 2196, finish = 4766
21/03/23 21:31:08 INFO PythonUDFRunner: Times: total = 7601, boot = -172, init = 200, finish = 7573
21/03/23 21:31:08 INFO PythonUDFRunner: Times: total = 7577, boot = -192, init = 805, finish = 6964
21/03/23 21:31:08 INFO PythonUDFRunner: Times: total = 6799, boot = -160, init = 2389, finish = 4570
21/03/23 21:31:08 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000076_77' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000076
21/03/23 21:31:08 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000076_77: Committed
21/03/23 21:31:08 INFO Executor: Finished task 76.0 in stage 1.0 (TID 77). 3592 bytes result sent to driver
21/03/23 21:31:08 INFO TaskSetManager: Finished task 76.0 in stage 1.0 (TID 77) in 6972 ms on localhost (executor driver) (74/81)
21/03/23 21:31:08 INFO PythonUDFRunner: Times: total = 7597, boot = -90, init = 1981, finish = 5706
21/03/23 21:31:09 INFO PythonUDFRunner: Times: total = 7556, boot = -148, init = 2204, finish = 5500
21/03/23 21:31:09 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000073_74' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000073
21/03/23 21:31:09 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000073_74: Committed
21/03/23 21:31:09 INFO Executor: Finished task 73.0 in stage 1.0 (TID 74). 3592 bytes result sent to driver
21/03/23 21:31:09 INFO TaskSetManager: Finished task 73.0 in stage 1.0 (TID 74) in 7700 ms on localhost (executor driver) (75/81)
21/03/23 21:31:09 INFO PythonUDFRunner: Times: total = 7599, boot = -161, init = 200, finish = 7560
21/03/23 21:31:09 INFO PythonUDFRunner: Times: total = 7471, boot = -236, init = 750, finish = 6957
21/03/23 21:31:09 INFO PythonUDFRunner: Times: total = 7451, boot = -181, init = 1498, finish = 6134
21/03/23 21:31:09 INFO PythonUDFRunner: Times: total = 7435, boot = -282, init = 1895, finish = 5822
21/03/23 21:31:09 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000074_75' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000074
21/03/23 21:31:09 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000074_75: Committed
21/03/23 21:31:09 INFO Executor: Finished task 74.0 in stage 1.0 (TID 75). 3592 bytes result sent to driver
21/03/23 21:31:09 INFO TaskSetManager: Finished task 74.0 in stage 1.0 (TID 75) in 7706 ms on localhost (executor driver) (76/81)
21/03/23 21:31:09 INFO PythonUDFRunner: Times: total = 8103, boot = -146, init = 174, finish = 8075
21/03/23 21:31:09 INFO PythonUDFRunner: Times: total = 8092, boot = -89, init = 787, finish = 7394
21/03/23 21:31:09 INFO PythonUDFRunner: Times: total = 8071, boot = -113, init = 2338, finish = 5846
21/03/23 21:31:09 INFO PythonUDFRunner: Times: total = 8048, boot = -104, init = 2561, finish = 5591
21/03/23 21:31:09 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000072_73' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000072
21/03/23 21:31:09 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000072_73: Committed
21/03/23 21:31:09 INFO Executor: Finished task 72.0 in stage 1.0 (TID 73). 3635 bytes result sent to driver
21/03/23 21:31:09 INFO TaskSetManager: Finished task 72.0 in stage 1.0 (TID 73) in 8192 ms on localhost (executor driver) (77/81)
21/03/23 21:31:09 INFO PythonUDFRunner: Times: total = 8083, boot = -203, init = 240, finish = 8046
21/03/23 21:31:09 INFO PythonUDFRunner: Times: total = 8043, boot = -225, init = 819, finish = 7449
21/03/23 21:31:09 INFO PythonUDFRunner: Times: total = 8054, boot = -288, init = 2208, finish = 6134
21/03/23 21:31:09 INFO PythonUDFRunner: Times: total = 8029, boot = -193, init = 2400, finish = 5822
21/03/23 21:31:09 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000075_76' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000075
21/03/23 21:31:09 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000075_76: Committed
21/03/23 21:31:09 INFO Executor: Finished task 75.0 in stage 1.0 (TID 76). 3592 bytes result sent to driver
21/03/23 21:31:09 INFO TaskSetManager: Finished task 75.0 in stage 1.0 (TID 76) in 8172 ms on localhost (executor driver) (78/81)
21/03/23 21:31:09 INFO PythonUDFRunner: Times: total = 4670, boot = -151, init = 186, finish = 4635
21/03/23 21:31:09 INFO PythonUDFRunner: Times: total = 4674, boot = -190, init = 1069, finish = 3795
21/03/23 21:31:09 INFO PythonUDFRunner: Times: total = 7272, boot = -218, init = 303, finish = 7187
21/03/23 21:31:09 INFO PythonUDFRunner: Times: total = 4689, boot = -118, init = 2183, finish = 2624
21/03/23 21:31:09 INFO PythonUDFRunner: Times: total = 7233, boot = -272, init = 999, finish = 6506
21/03/23 21:31:09 INFO PythonUDFRunner: Times: total = 4694, boot = -176, init = 2370, finish = 2500
21/03/23 21:31:09 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000079_80' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000079
21/03/23 21:31:09 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000079_80: Committed
21/03/23 21:31:09 INFO Executor: Finished task 79.0 in stage 1.0 (TID 80). 3592 bytes result sent to driver
21/03/23 21:31:09 INFO TaskSetManager: Finished task 79.0 in stage 1.0 (TID 80) in 4804 ms on localhost (executor driver) (79/81)
21/03/23 21:31:09 INFO PythonUDFRunner: Times: total = 7263, boot = -135, init = 2620, finish = 4778
21/03/23 21:31:09 INFO PythonUDFRunner: Times: total = 6964, boot = -266, init = 299, finish = 6931
21/03/23 21:31:09 INFO PythonUDFRunner: Times: total = 6983, boot = -210, init = 1170, finish = 6023
21/03/23 21:31:09 INFO PythonUDFRunner: Times: total = 7303, boot = -141, init = 2882, finish = 4562
21/03/23 21:31:09 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000077_78' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000077
21/03/23 21:31:09 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000077_78: Committed
21/03/23 21:31:09 INFO Executor: Finished task 77.0 in stage 1.0 (TID 78). 3592 bytes result sent to driver
21/03/23 21:31:09 INFO TaskSetManager: Finished task 77.0 in stage 1.0 (TID 78) in 7394 ms on localhost (executor driver) (80/81)
21/03/23 21:31:09 INFO PythonUDFRunner: Times: total = 6981, boot = -174, init = 2849, finish = 4306
21/03/23 21:31:09 INFO PythonUDFRunner: Times: total = 6970, boot = -197, init = 3075, finish = 4092
21/03/23 21:31:09 INFO FileOutputCommitter: Saved output of task 'attempt_20210323213023_0001_m_000078_79' to file:/results/output/zillow/Z2/pyspark_pypy3_df/_temporary/0/task_20210323213023_0001_m_000078
21/03/23 21:31:09 INFO SparkHadoopMapRedUtil: attempt_20210323213023_0001_m_000078_79: Committed
21/03/23 21:31:09 INFO Executor: Finished task 78.0 in stage 1.0 (TID 79). 3592 bytes result sent to driver
21/03/23 21:31:09 INFO TaskSetManager: Finished task 78.0 in stage 1.0 (TID 79) in 7085 ms on localhost (executor driver) (81/81)
21/03/23 21:31:09 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/03/23 21:31:09 INFO DAGScheduler: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0) finished in 45.956 s
21/03/23 21:31:09 INFO DAGScheduler: Job 1 finished: csv at NativeMethodAccessorImpl.java:0, took 45.965971 s
21/03/23 21:31:09 INFO FileFormatWriter: Write Job 622b4e12-96c6-469f-99d0-f394a64aa3c2 committed.
21/03/23 21:31:09 INFO FileFormatWriter: Finished processing stats for write job 622b4e12-96c6-469f-99d0-f394a64aa3c2.
21/03/23 21:31:10 INFO SparkContext: Invoking stop() from shutdown hook
21/03/23 21:31:10 INFO SparkUI: Stopped Spark web UI at http://4e1bb76d17c5:4040
21/03/23 21:31:10 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/23 21:31:10 INFO MemoryStore: MemoryStore cleared
21/03/23 21:31:10 INFO BlockManager: BlockManager stopped
21/03/23 21:31:10 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/23 21:31:10 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/23 21:31:10 INFO SparkContext: Successfully stopped SparkContext
21/03/23 21:31:10 INFO ShutdownHookManager: Shutdown hook called
21/03/23 21:31:10 INFO ShutdownHookManager: Deleting directory /tmp/spark-f604d0d7-532a-4f22-878a-46f5e3375554
21/03/23 21:31:10 INFO ShutdownHookManager: Deleting directory /tmp/spark-e45bfc47-b63c-4853-8e01-eb5a1ff71baf
21/03/23 21:31:10 INFO ShutdownHookManager: Deleting directory /tmp/spark-f604d0d7-532a-4f22-878a-46f5e3375554/pyspark-5a2cce52-a12b-4afc-9dc3-967ed833e8ac
