/opt/pypy3/site-packages/distributed/node.py:155: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37763 instead
  http_address["port"], self.http_server.port
RPython traceback:
  File "rpython_jit_metainterp.c", line 21500, in handle_jitexception_7
  File "rpython_jit_metainterp_1.c", line 1639, in execute_assembler__star_2_2
  File "rpython_jit_metainterp.c", line 2424, in ResumeGuardForcedDescr_handle_fail
  File "rpython_jit_metainterp.c", line 4382, in resume_in_blackhole
  File "rpython_jit_metainterp.c", line 9005, in blackhole_from_resumedata
  File "rpython_jit_codewriter.c", line 123, in enumerate_vars__unique_id
  File "rpython_jit_metainterp.c", line 10854, in ResumeDataDirectReader_getvirtual_ptr
Fatal RPython error: AssertionError
distributed.nanny - WARNING - Restarting worker
RPython traceback:
  File "rpython_jit_metainterp.c", line 21500, in handle_jitexception_7
  File "rpython_jit_metainterp_1.c", line 1639, in execute_assembler__star_2_2
  File "rpython_jit_metainterp.c", line 2424, in ResumeGuardForcedDescr_handle_fail
  File "rpython_jit_metainterp.c", line 4382, in resume_in_blackhole
  File "rpython_jit_metainterp.c", line 9005, in blackhole_from_resumedata
  File "rpython_jit_codewriter.c", line 123, in enumerate_vars__unique_id
  File "rpython_jit_metainterp.c", line 10854, in ResumeDataDirectReader_getvirtual_ptr
Fatal RPython error: AssertionError
distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:38789
Traceback (most recent call last):
  File "/opt/pypy3/site-packages/distributed/comm/tcp.py", line 195, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
  File "/opt/pypy3/lib-python/3/asyncio/futures.py", line 327, in __iter__
    yield self  # This tells Task to wait for completion.
  File "/opt/pypy3/lib-python/3/asyncio/tasks.py", line 250, in _wakeup
    future.result()
  File "/opt/pypy3/lib-python/3/asyncio/futures.py", line 243, in result
    raise self._exception
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/pypy3/site-packages/distributed/worker.py", line 2064, in gather_dep
    self.rpc, deps, worker, who=self.address
  File "/opt/pypy3/site-packages/distributed/worker.py", line 3333, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/opt/pypy3/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/opt/pypy3/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/opt/pypy3/site-packages/distributed/worker.py", line 3320, in _get_data
    max_connections=max_connections,
  File "/opt/pypy3/site-packages/distributed/core.py", line 644, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/pypy3/site-packages/distributed/comm/tcp.py", line 205, in read
    convert_stream_closed_error(self, e)
  File "/opt/pypy3/site-packages/distributed/comm/tcp.py", line 128, in convert_stream_closed_error
    raise CommClosedError("in %s: %s" % (obj, exc)) from exc
distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed
distributed.nanny - WARNING - Restarting worker
RPython traceback:
  File "rpython_jit_metainterp.c", line 21500, in handle_jitexception_7
  File "rpython_jit_metainterp_1.c", line 1639, in execute_assembler__star_2_2
  File "rpython_jit_metainterp.c", line 2424, in ResumeGuardForcedDescr_handle_fail
  File "rpython_jit_metainterp.c", line 4382, in resume_in_blackhole
  File "rpython_jit_metainterp.c", line 9005, in blackhole_from_resumedata
  File "rpython_jit_codewriter.c", line 123, in enumerate_vars__unique_id
  File "rpython_jit_metainterp.c", line 10854, in ResumeDataDirectReader_getvirtual_ptr
Fatal RPython error: AssertionError
distributed.nanny - WARNING - Restarting worker
RPython traceback:
  File "rpython_jit_metainterp.c", line 21500, in handle_jitexception_7
  File "rpython_jit_metainterp_1.c", line 1639, in execute_assembler__star_2_2
  File "rpython_jit_metainterp.c", line 2424, in ResumeGuardForcedDescr_handle_fail
  File "rpython_jit_metainterp.c", line 4382, in resume_in_blackhole
  File "rpython_jit_metainterp.c", line 9005, in blackhole_from_resumedata
  File "rpython_jit_codewriter.c", line 123, in enumerate_vars__unique_id
  File "rpython_jit_metainterp.c", line 10854, in ResumeDataDirectReader_getvirtual_ptr
Fatal RPython error: AssertionError
distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:45199
Traceback (most recent call last):
  File "/opt/pypy3/site-packages/distributed/comm/tcp.py", line 195, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
  File "/opt/pypy3/lib-python/3/asyncio/futures.py", line 327, in __iter__
    yield self  # This tells Task to wait for completion.
  File "/opt/pypy3/lib-python/3/asyncio/tasks.py", line 250, in _wakeup
    future.result()
  File "/opt/pypy3/lib-python/3/asyncio/futures.py", line 243, in result
    raise self._exception
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/pypy3/site-packages/distributed/worker.py", line 2064, in gather_dep
    self.rpc, deps, worker, who=self.address
  File "/opt/pypy3/site-packages/distributed/worker.py", line 3333, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/opt/pypy3/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/opt/pypy3/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/opt/pypy3/site-packages/distributed/worker.py", line 3320, in _get_data
    max_connections=max_connections,
  File "/opt/pypy3/site-packages/distributed/core.py", line 644, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/pypy3/site-packages/distributed/comm/tcp.py", line 205, in read
    convert_stream_closed_error(self, e)
  File "/opt/pypy3/site-packages/distributed/comm/tcp.py", line 128, in convert_stream_closed_error
    raise CommClosedError("in %s: %s" % (obj, exc)) from exc
distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed
distributed.nanny - WARNING - Restarting worker
distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:45199
Traceback (most recent call last):
  File "/opt/pypy3/site-packages/distributed/comm/tcp.py", line 195, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
  File "/opt/pypy3/lib-python/3/asyncio/futures.py", line 327, in __iter__
    yield self  # This tells Task to wait for completion.
  File "/opt/pypy3/lib-python/3/asyncio/tasks.py", line 250, in _wakeup
    future.result()
  File "/opt/pypy3/lib-python/3/asyncio/futures.py", line 243, in result
    raise self._exception
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/pypy3/site-packages/distributed/worker.py", line 2064, in gather_dep
    self.rpc, deps, worker, who=self.address
  File "/opt/pypy3/site-packages/distributed/worker.py", line 3333, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/opt/pypy3/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/opt/pypy3/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/opt/pypy3/site-packages/distributed/worker.py", line 3320, in _get_data
    max_connections=max_connections,
  File "/opt/pypy3/site-packages/distributed/core.py", line 644, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/pypy3/site-packages/distributed/comm/tcp.py", line 205, in read
    convert_stream_closed_error(self, e)
  File "/opt/pypy3/site-packages/distributed/comm/tcp.py", line 128, in convert_stream_closed_error
    raise CommClosedError("in %s: %s" % (obj, exc)) from exc
distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed
distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:45199
Traceback (most recent call last):
  File "/opt/pypy3/site-packages/distributed/comm/tcp.py", line 263, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/pypy3/site-packages/distributed/worker.py", line 2064, in gather_dep
    self.rpc, deps, worker, who=self.address
  File "/opt/pypy3/site-packages/distributed/worker.py", line 3333, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/opt/pypy3/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/opt/pypy3/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/opt/pypy3/site-packages/distributed/worker.py", line 3320, in _get_data
    max_connections=max_connections,
  File "/opt/pypy3/site-packages/distributed/core.py", line 642, in send_recv
    await comm.write(msg, serializers=serializers, on_error="raise")
  File "/opt/pypy3/site-packages/distributed/comm/tcp.py", line 279, in write
    convert_stream_closed_error(self, e)
  File "/opt/pypy3/site-packages/distributed/comm/tcp.py", line 128, in convert_stream_closed_error
    raise CommClosedError("in %s: %s" % (obj, exc)) from exc
distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed
RPython traceback:
  File "rpython_jit_metainterp.c", line 22541, in BlackholeInterpreter__resume_mainloop
  File "rpython_jit_metainterp.c", line 40172, in BlackholeInterpreter_handle_exception_in_frame
Exception in thread Profile:
Traceback (most recent call last):
  File "/opt/pypy3/lib-python/3/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/opt/pypy3/lib-python/3/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/opt/pypy3/site-packages/distributed/profile.py", line 268, in _watch
    process(frame, None, recent, omit=omit)
  File "/opt/pypy3/site-packages/distributed/profile.py", line 103, in process
    state = process(prev, frame, state, stop=stop)
  File "/opt/pypy3/site-packages/distributed/profile.py", line 103, in process
    state = process(prev, frame, state, stop=stop)
  File "/opt/pypy3/site-packages/distributed/profile.py", line 99, in process
    prev = frame.f_back
SystemError: unexpected internal exception (please report a bug): <InvalidVirtualRef object at 0x7f5f875de168>; internal traceback was dumped to stderr

